#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹ - Webåº”ç”¨

æ•´åˆäº†è§†é¢‘ä¸Šä¼ ã€å¤„ç†ã€è½¬å½•ã€é—®ç­”ç­‰åŠŸèƒ½çš„å®Œæ•´Webåº”ç”¨
"""

import os
import sys
import time
import json
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import gradio as gr

os.environ['SSL_VERIFY'] = 'false'

# å°è¯•å¯¼å…¥åç«¯æ¨¡å—ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
MOCK_MODE = False
import_error = None

try:
    from modules.video.video_loader import VideoLoader
    print("âœ“ VideoLoader å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"VideoLoader å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.video.audio_extractor import AudioExtractor
    print("âœ“ AudioExtractor å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"AudioExtractor å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.speech.whisper_asr import WhisperASR
    print("âœ“ WhisperASR å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"WhisperASR å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.utils.file_manager import FileManager
    print("âœ“ FileManager å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"FileManager å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.text.translator import TextTranslator
    print("âœ“ TextTranslator å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— TextTranslator å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.vector_store import VectorStore
    print("âœ“ VectorStore å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— VectorStore å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.bm25_retriever import BM25Retriever
    print("âœ“ BM25Retriever å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— BM25Retriever å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.hybrid_retriever import HybridRetriever
    print("âœ“ HybridRetriever å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— HybridRetriever å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.utils.video_cleaner import register_video_cleanup, get_video_cleanup_info, cleanup_videos_now
    print("âœ“ VideoCleaner å¯¼å…¥æˆåŠŸ")
    # æ³¨å†Œé€€å‡ºæ—¶æ¸…ç†è§†é¢‘æ–‡ä»¶
    register_video_cleanup()
    print("âœ“ è§†é¢‘æ¸…ç†åŠŸèƒ½å·²å¯ç”¨ï¼Œç¨‹åºé€€å‡ºæ—¶å°†è‡ªåŠ¨æ¸…ç†ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶")
except ImportError as e:
    print(f"âœ— VideoCleaner å¯¼å…¥å¤±è´¥: {e}")
    register_video_cleanup = None
    get_video_cleanup_info = None
    cleanup_videos_now = None

if MOCK_MODE:
    print(f"\nè­¦å‘Šï¼šå°†åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œ")
    print(f"é”™è¯¯åŸå› ï¼š{import_error}")
    print("è¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–ï¼špip install -r requirements.txt\n")
    
    # æ¨¡æ‹Ÿç±» - ä»…ç”¨äºå‰ç«¯å±•ç¤º
    class VideoLoader:
        def validate_video(self, video_path):
            import os
            file_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0
            return {
                "file_path": str(video_path),
                "file_name": os.path.basename(video_path),
                "file_size": file_size,
                "file_size_mb": round(file_size / (1024 * 1024), 2),
                "format": os.path.splitext(video_path)[1],
                "resolution": "1920x1080",
                "width": 1920,
                "height": 1080,
                "fps": 30.0,
                "frame_count": 9000,
                "duration": 300.0,
                "duration_formatted": "05:00",
                "aspect_ratio": 1.78,
                "validation_status": "passed"
            }
    
    class AudioExtractor:
        def extract_audio(self, video_path):
            import tempfile
            temp_dir = Path(tempfile.gettempdir()) / "ai_video_assistant"
            temp_dir.mkdir(parents=True, exist_ok=True)
            audio_path = temp_dir / f"{Path(video_path).stem}_extracted.wav"
            # åˆ›å»ºä¸€ä¸ªç©ºçš„éŸ³é¢‘æ–‡ä»¶ä½œä¸ºæ¨¡æ‹Ÿ
            audio_path.touch()
            return audio_path
    
    class WhisperASR:
        def __init__(self, model_size="base"):
            self.model_size = model_size
        
        def transcribe(self, audio_path):
            return {
                "audio_file": str(audio_path),
                "audio_file_name": Path(audio_path).name,
                "language": "zh",
                "language_probability": 0.9,
                "text": "è¿™æ˜¯æ¨¡æ‹Ÿçš„è½¬å½•æ–‡æœ¬ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯Whisperæ¨¡å‹ç”Ÿæˆçš„çœŸå®è½¬å½•ç»“æœã€‚",
                "segments": [
                    {
                        "id": 0,
                        "start": 0.0,
                        "end": 5.0,
                        "text": "è¿™æ˜¯ç¬¬ä¸€æ®µæ¨¡æ‹Ÿè½¬å½•æ–‡æœ¬ã€‚",
                        "confidence": 0.95,
                        "no_speech_prob": 0.01,
                        "words": []
                    },
                    {
                        "id": 1,
                        "start": 5.0,
                        "end": 10.0,
                        "text": "è¿™æ˜¯ç¬¬äºŒæ®µæ¨¡æ‹Ÿè½¬å½•æ–‡æœ¬ã€‚",
                        "confidence": 0.93,
                        "no_speech_prob": 0.02,
                        "words": []
                    }
                ],
                "words": [],
                "model_used": self.model_size,
                "device_used": "cpu",
                "total_duration": 10.0,
                "avg_confidence": 0.94,
                "speech_duration": 10.0,
                "speech_ratio": 1.0
            }
    
    class FileManager:
        def save_transcript_json(self, transcript_data, output_path):
            import json
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transcript_data, f, ensure_ascii=False, indent=2)
        
        def save_transcript_text(self, transcript_data, output_path):
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(transcript_data["text"])


# å…¨å±€å˜é‡å­˜å‚¨å¤„ç†çŠ¶æ€
processing_status = {}
video_data = {}


# ç¿»è¯‘è¿›åº¦å›è°ƒå‡½æ•°
def update_translation_progress(video_id, current, total, message):
    """æ›´æ–°ç¿»è¯‘è¿›åº¦"""
    if video_id not in video_data:
        return
    
    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
    if total > 0:
        progress = min(current / total, 1.0)
    else:
        progress = 0.0
    
    # æ›´æ–°è§†é¢‘æ•°æ®ä¸­çš„ç¿»è¯‘è¿›åº¦
    video_data[video_id]["translation_progress"] = {
        "current": current,
        "total": total,
        "progress": progress,
        "message": message,
        "timestamp": time.time()
    }


class VideoAssistant:
    """è§†é¢‘åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self, cuda_enabled=True, whisper_model="base"):
        """åˆå§‹åŒ–è§†é¢‘åŠ©æ‰‹
        
        Args:
            cuda_enabled: æ˜¯å¦å¯ç”¨CUDAåŠ é€Ÿ
            whisper_model: Whisperæ¨¡å‹å¤§å°
        """
        self.video_loader = VideoLoader()
        self.audio_extractor = AudioExtractor()
        
        # è®¾ç½®è®¾å¤‡
        device = "cuda" if cuda_enabled and torch.cuda.is_available() else "cpu"
        self.whisper_asr = WhisperASR(model_size=whisper_model, device=device)
        self.file_manager = FileManager()
        
        # ç¿»è¯‘è¿›åº¦è·Ÿè¸ª
        self.translation_progress = {}
        
        # åˆå§‹åŒ–ç¿»è¯‘å™¨å’Œæ£€ç´¢å™¨
        if not MOCK_MODE:
            try:
                self.translator = TextTranslator(
                    default_method="deep-translator",
                    progress_callback=self._on_translation_progress
                )
                print("âœ“ ç¿»è¯‘å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨deep-translatorï¼‰")
            except Exception as e:
                print(f"âš  ç¿»è¯‘å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.translator = None
            
            try:
                self.vector_store = VectorStore(mirror_site="tuna")  # ä½¿ç”¨æ¸…åé•œåƒ
                print("âœ“ å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš  å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.vector_store = None
            
            try:
                self.bm25_retriever = BM25Retriever(language='auto')
                print("âœ“ BM25æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš  BM25æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.bm25_retriever = None
            
            # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
            if self.vector_store and self.bm25_retriever:
                try:
                    self.hybrid_retriever = HybridRetriever(
                        vector_store=self.vector_store,
                        bm25_retriever=self.bm25_retriever,
                        vector_weight=0.6,
                        bm25_weight=0.4,
                        fusion_method="weighted_average"
                    )
                    print("âœ“ æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    print(f"âš  æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                    self.hybrid_retriever = None
            else:
                self.hybrid_retriever = None
        else:
            self.translator = None
            self.vector_store = None
            self.bm25_retriever = None
            self.hybrid_retriever = None
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs("data/uploads", exist_ok=True)
        os.makedirs("data/transcripts", exist_ok=True)
        os.makedirs("data/temp", exist_ok=True)
        os.makedirs("data/vectors", exist_ok=True)
        
        # å¯¹è¯é“¾ç®¡ç†
        self.conversation_chains = {}
    
    def _on_translation_progress(self, current: int, total: int, message: str):
        """ç¿»è¯‘è¿›åº¦å›è°ƒå‡½æ•°"""
        # è¿™é‡Œéœ€è¦è·å–å½“å‰æ­£åœ¨ç¿»è¯‘çš„è§†é¢‘ID
        # ç”±äºç¿»è¯‘å™¨æ˜¯å…¨å±€çš„ï¼Œæˆ‘ä»¬éœ€è¦ä»æŸä¸ªåœ°æ–¹è·å–å½“å‰è§†é¢‘ID
        # æˆ‘ä»¬å°†åœ¨translate_transcriptæ–¹æ³•ä¸­è®¾ç½®å½“å‰è§†é¢‘ID
        if hasattr(self, '_current_translating_video_id'):
            video_id = self._current_translating_video_id
            update_translation_progress(video_id, current, total, message)
    
    def upload_and_process_video(self, video_file, user_id=None, cuda_enabled=True, whisper_model="base"):
        """
        ä¸Šä¼ è§†é¢‘å¹¶è‡ªåŠ¨å¼€å§‹å¤„ç†
        """
        if video_file is None:
            return {
                "status": "error",
                "message": "è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶"
            }
        
        try:
            # ç”Ÿæˆå”¯ä¸€çš„è§†é¢‘ID
            video_path = Path(video_file)
            video_id = f"video_{int(time.time())}_{video_path.stem}"
            
            # å¤åˆ¶æ–‡ä»¶åˆ°ä¸Šä¼ ç›®å½•
            upload_path = Path(f"data/uploads/{video_id}{video_path.suffix}")
            import shutil
            shutil.copy2(video_file, upload_path)
            
            # éªŒè¯è§†é¢‘
            video_info = self.video_loader.validate_video(upload_path)
            
            # ä¿å­˜è§†é¢‘ä¿¡æ¯
            video_data[video_id] = {
                "video_id": video_id,
                "filename": video_path.name,
                "file_path": str(upload_path),
                "video_info": video_info,
                "status": "uploaded",
                "transcript": None,
                "assistant_config": {
                    "cuda_enabled": cuda_enabled,
                    "whisper_model": whisper_model
                },
                "upload_time": time.time()
            }
            
            # å¼€å§‹å¤„ç†
            processing_status[video_id] = {
                "progress": 0.0,
                "current_step": "å¼€å§‹å¤„ç†...",
                "log_messages": [f"[{time.strftime('%H:%M:%S')}] è§†é¢‘ä¸Šä¼ æˆåŠŸ: {video_path.name}"],
                "status": "processing"
            }
            
            return {
                "video_id": video_id,
                "filename": video_path.name,
                "status": "processing",
                "message": "è§†é¢‘ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹å¤„ç†..."
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}"
            }
    
    def get_processing_progress(self, video_id):
        """
        è·å–è§†é¢‘å¤„ç†è¿›åº¦
        """
        if video_id not in processing_status:
            return {
                "progress": 0.0,
                "current_step": "æœªæ‰¾åˆ°å¤„ç†ä»»åŠ¡",
                "log_messages": [],
                "status": "error"
            }
        
        # å¦‚æœè¿˜åœ¨å¤„ç†ä¸­ï¼Œç»§ç»­å¤„ç†
        if processing_status[video_id]["status"] == "processing":
            self._continue_processing(video_id)
        
        return processing_status[video_id]
    
    def _continue_processing(self, video_id, cuda_enabled=True, whisper_model="base"):
        """
        ç»§ç»­å¤„ç†è§†é¢‘
        """
        if video_id not in video_data:
            return
        
        status = processing_status[video_id]
        video_info = video_data[video_id]
        
        try:
            progress = status["progress"]
            
            if progress < 0.2:
                # æå–éŸ³é¢‘
                status["current_step"] = "æå–éŸ³é¢‘ä¸­..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹æå–éŸ³é¢‘")
                status["progress"] = 0.2
                
                video_path = Path(video_info["file_path"])
                audio_path = self.audio_extractor.extract_audio(video_path)
                video_info["audio_path"] = str(audio_path)
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] éŸ³é¢‘æå–å®Œæˆ")
                
            elif progress < 0.7:
                # è¯­éŸ³è½¬æ–‡æœ¬
                status["current_step"] = "è¯­éŸ³è½¬æ–‡æœ¬ä¸­..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹è¯­éŸ³è½¬æ–‡æœ¬")
                status["progress"] = 0.7
                
                if "audio_path" in video_info:
                    audio_path = Path(video_info["audio_path"])
                    transcript_result = self.whisper_asr.transcribe(audio_path)
                    video_info["transcript"] = transcript_result
                    
                    # ä¿å­˜è½¬å½•ç»“æœ
                    transcript_path = Path(f"data/transcripts/{video_id}_transcript.json")
                    self.file_manager.save_transcript_json(transcript_result, transcript_path)
                    
                    status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] è¯­éŸ³è½¬æ–‡æœ¬å®Œæˆ")
                    
                    # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    if audio_path.exists():
                        audio_path.unlink()
                        
            elif progress < 0.9:
                # å¤„ç†æµç¨‹ä¸­çš„å…¶ä»–æ­¥éª¤
                status["current_step"] = "å‡†å¤‡å®Œæˆ..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] å¤„ç†å³å°†å®Œæˆ")
                status["progress"] = 0.9
                    
            else:
                # å¤„ç†å®Œæˆ
                status["progress"] = 1.0
                status["current_step"] = "å¤„ç†å®Œæˆ"
                status["status"] = "completed"
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] æ‰€æœ‰å¤„ç†ä»»åŠ¡å®Œæˆ")
                video_info["status"] = "completed"
                
        except Exception as e:
            status["status"] = "error"
            status["current_step"] = f"å¤„ç†å¤±è´¥: {str(e)}"
            status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] é”™è¯¯: {str(e)}")
    
    
    
    def get_video_info(self, video_id):
        """
        è·å–è§†é¢‘ä¿¡æ¯
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        return video_data[video_id]
    
    def get_video_list(self, user_id=None):
        """
        è·å–è§†é¢‘åˆ—è¡¨
        """
        videos = []
        for video_id, info in video_data.items():
            if info["status"] == "completed":
                videos.append({
                    "video_id": video_id,
                    "filename": info["filename"],
                    "thumbnail": "",  # å¯ä»¥æ·»åŠ ç¼©ç•¥å›¾ç”Ÿæˆ
                    "upload_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(info["upload_time"])),
                    "config": info.get("assistant_config", {"cuda_enabled": True, "whisper_model": "base"})
                })
        
        return videos
    
    def _create_conversation_chain(self, video_id):
        """ä¸ºè§†é¢‘åˆ›å»ºå¯¹è¯é“¾"""
        if not MOCK_MODE:
            try:
                # å¯¼å…¥å¯¹è¯é“¾
                from modules.qa.conversation_chain import ConversationChain
                
                # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                vector_index_path = f"data/vectors/{video_id}_vector_index.pkl"
                bm25_index_path = f"data/vectors/{video_id}_bm25_index.pkl"
                
                import os
                if not os.path.exists(vector_index_path) or not os.path.exists(bm25_index_path):
                    print(f"ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ— æ£€ç´¢å™¨çš„å¯¹è¯é“¾")
                    # åˆ›å»ºæ— æ£€ç´¢å™¨çš„å¯¹è¯é“¾ï¼Œä»ç„¶å¯ä»¥è¿›è¡ŒåŸºæœ¬å¯¹è¯
                    return ConversationChain()
                
                # åˆ›å»ºæ£€ç´¢å™¨
                vector_store = VectorStore()
                vector_store.load_index(vector_index_path)
                
                bm25_retriever = BM25Retriever()
                bm25_retriever.load_index(bm25_index_path)
                
                hybrid_retriever = HybridRetriever(
                    vector_store=vector_store,
                    bm25_retriever=bm25_retriever
                )
                
                # åˆ›å»ºå¸¦æ£€ç´¢å™¨çš„å¯¹è¯é“¾
                conversation_chain = ConversationChain(retriever=hybrid_retriever)
                
                # è®¾ç½®è½¬å½•å†…å®¹
                transcript_file = f"data/transcripts/{video_id}_transcript.json"
                if os.path.exists(transcript_file):
                    import json
                    with open(transcript_file, 'r', encoding='utf-8') as f:
                        transcript_data = json.load(f)
                        if 'segments' in transcript_data:
                            conversation_chain.set_full_transcript(transcript_data['segments'])
                            print(f"å·²ä¸ºè§†é¢‘ {video_id} è®¾ç½®è½¬å½•å†…å®¹ï¼Œå…± {len(transcript_data['segments'])} ä¸ªç‰‡æ®µ")
                            # è°ƒè¯•ï¼šéªŒè¯è½¬å½•å†…å®¹æ˜¯å¦è®¾ç½®æˆåŠŸ
                            if hasattr(conversation_chain, 'full_transcript') and conversation_chain.full_transcript:
                                print(f"è½¬å½•å†…å®¹è®¾ç½®æˆåŠŸï¼Œç¬¬ä¸€æ®µå†…å®¹: {conversation_chain.full_transcript[0].get('text', '')[:50]}...")
                            else:
                                print("è­¦å‘Šï¼šè½¬å½•å†…å®¹è®¾ç½®å¤±è´¥ï¼")
                        else:
                            print(f"è­¦å‘Šï¼šè½¬å½•æ–‡ä»¶ä¸­æ²¡æœ‰segmentså­—æ®µï¼Œæ–‡ä»¶å†…å®¹: {list(transcript_data.keys())}")
                else:
                    print(f"è­¦å‘Šï¼šè½¬å½•æ–‡ä»¶ä¸å­˜åœ¨: {transcript_file}")
                
                return conversation_chain
            except Exception as e:
                print(f"åˆ›å»ºå¯¹è¯é“¾å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬å¯¹è¯é“¾: {e}")
                # å³ä½¿æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥ï¼Œä¹Ÿè¿”å›åŸºæœ¬å¯¹è¯é“¾
                try:
                    from modules.qa.conversation_chain import ConversationChain
                    conversation_chain = ConversationChain()
                    
                    # è®¾ç½®è½¬å½•å†…å®¹
                    transcript_file = f"data/transcripts/{video_id}_transcript.json"
                    if os.path.exists(transcript_file):
                        import json
                        with open(transcript_file, 'r', encoding='utf-8') as f:
                            transcript_data = json.load(f)
                            if 'segments' in transcript_data:
                                conversation_chain.set_full_transcript(transcript_data['segments'])
                                print(f"å·²ä¸ºè§†é¢‘ {video_id} è®¾ç½®è½¬å½•å†…å®¹ï¼Œå…± {len(transcript_data['segments'])} ä¸ªç‰‡æ®µ")
                                # è°ƒè¯•ï¼šéªŒè¯è½¬å½•å†…å®¹æ˜¯å¦è®¾ç½®æˆåŠŸ
                                if hasattr(conversation_chain, 'full_transcript') and conversation_chain.full_transcript:
                                    print(f"è½¬å½•å†…å®¹è®¾ç½®æˆåŠŸï¼Œç¬¬ä¸€æ®µå†…å®¹: {conversation_chain.full_transcript[0].get('text', '')[:50]}...")
                                else:
                                    print("è­¦å‘Šï¼šè½¬å½•å†…å®¹è®¾ç½®å¤±è´¥ï¼")
                            else:
                                print(f"è­¦å‘Šï¼šè½¬å½•æ–‡ä»¶ä¸­æ²¡æœ‰segmentså­—æ®µï¼Œæ–‡ä»¶å†…å®¹: {list(transcript_data.keys())}")
                    else:
                        print(f"è­¦å‘Šï¼šè½¬å½•æ–‡ä»¶ä¸å­˜åœ¨: {transcript_file}")
                    
                    return conversation_chain
                except Exception as e2:
                    print(f"åˆ›å»ºåŸºæœ¬å¯¹è¯é“¾ä¹Ÿå¤±è´¥: {e2}")
                    return None
        return None
    
    def chat_with_video(self, video_id, question, chat_history, temperature=0.7):
        """
        åŸºäºè§†é¢‘å†…å®¹è¿›è¡Œé—®ç­”
        """
        if video_id not in video_data:
            return "è§†é¢‘ä¸å­˜åœ¨", chat_history
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return "è§†é¢‘å°šæœªå¤„ç†å®Œæˆï¼Œæ— æ³•è¿›è¡Œé—®ç­”", chat_history
        
        # è·å–æˆ–åˆ›å»ºå¯¹è¯é“¾
        if video_id not in self.conversation_chains:
            self.conversation_chains[video_id] = self._create_conversation_chain(video_id)
        
        conversation_chain = self.conversation_chains[video_id]
        
        if conversation_chain is None:
            return "å¯¹è¯é“¾åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡å¯åº”ç”¨æˆ–è”ç³»ç®¡ç†å‘˜", chat_history
        
        # è°ƒè¯•ï¼šæ£€æŸ¥è½¬å½•å†…å®¹æ˜¯å¦å­˜åœ¨
        if hasattr(conversation_chain, 'full_transcript') and conversation_chain.full_transcript:
            print(f"å¯¹è¯ä¸­ï¼šè§†é¢‘ {video_id} æœ‰è½¬å½•å†…å®¹ï¼Œå…± {len(conversation_chain.full_transcript)} ä¸ªç‰‡æ®µ")
        else:
            print(f"å¯¹è¯ä¸­ï¼šè§†é¢‘ {video_id} æ²¡æœ‰è½¬å½•å†…å®¹ï¼")
        
        try:
            # è°ƒç”¨å¯¹è¯é“¾
            result = conversation_chain.chat(question)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ£€ç´¢ç»“æœ
            retrieved_docs = result.get('retrieved_docs', [])
            retrieved_count = len(retrieved_docs)
            
            # ç¡®ä¿æ£€ç´¢æ–‡æ¡£æ ¼å¼ä¸€è‡´ï¼ˆæå–å­—æ®µåˆ°é¡¶å±‚ï¼‰
            for doc in retrieved_docs:
                if 'document' in doc and 'text' not in doc:
                    # å¦‚æœæœ‰documentå¯¹è±¡ä½†æ²¡æœ‰é¡¶å±‚å­—æ®µï¼Œæå–å¸¸ç”¨å­—æ®µ
                    document = doc['document']
                    for key in ['text', 'start', 'end', 'confidence']:
                        if key in document:
                            doc[key] = document[key]
            
            if retrieved_count == 0:
                # å¦‚æœæ²¡æœ‰æ£€ç´¢ç»“æœï¼Œå¯èƒ½æ˜¯ç´¢å¼•æœªæ„å»º
                response = result['response']
                if "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹" not in response:
                    # æ·»åŠ æç¤ºä¿¡æ¯
                    response = f"{response}\n\nğŸ’¡ æç¤ºï¼šå¦‚éœ€åŸºäºè§†é¢‘å†…å®¹çš„ç²¾å‡†å›ç­”ï¼Œè¯·å…ˆåœ¨'å†…å®¹æœç´¢'ä¸­ç‚¹å‡»'æ„å»ºæ£€ç´¢ç´¢å¼•'æŒ‰é’®ã€‚"
            else:
                response = result['response']
            
            # ç¡®ä¿å†å²è®°å½•æ ¼å¼æ­£ç¡®
            if not isinstance(chat_history, list):
                chat_history = []
            
            # æ·»åŠ æ–°æ¶ˆæ¯åˆ°å†å²è®°å½•ï¼ˆä½¿ç”¨å­—å…¸æ ¼å¼ï¼‰
            chat_history.append({"role": "user", "content": question})
            chat_history.append({"role": "assistant", "content": response})
            
            return response, chat_history
        except Exception as e:
            return f"é—®ç­”å¤±è´¥: {str(e)}", chat_history
    
    # æ³¨æ„ï¼šé—®ç­”åŠŸèƒ½åœ¨modules/qa/ä¸­æœªå®ç°
    # éœ€è¦å®ç° modules/qa/conversation_chain.py ç­‰æ¨¡å—
    
    def translate_transcript(self, video_id, target_lang):
        """
        ç¿»è¯‘è½¬å½•æ–‡æœ¬
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.translator:
            return {"error": "ç¿»è¯‘å™¨æœªåˆå§‹åŒ–"}
        
        try:
            # è®¾ç½®å½“å‰æ­£åœ¨ç¿»è¯‘çš„è§†é¢‘IDï¼Œç”¨äºè¿›åº¦å›è°ƒ
            self._current_translating_video_id = video_id
            
            # åˆå§‹åŒ–ç¿»è¯‘è¿›åº¦
            video_info["translation_progress"] = {
                "current": 0,
                "total": 0,
                "progress": 0.0,
                "message": "å‡†å¤‡ç¿»è¯‘...",
                "timestamp": time.time()
            }
            
            transcript = video_info["transcript"]
            translated_transcript = self.translator.translate_transcript(transcript, target_lang)
            
            # ä¿å­˜ç¿»è¯‘ç»“æœ
            video_info[f"translated_transcript_{target_lang}"] = translated_transcript
            
            # æ›´æ–°ç¿»è¯‘å®ŒæˆçŠ¶æ€
            video_info["translation_progress"] = {
                "current": 1,
                "total": 1,
                "progress": 1.0,
                "message": "ç¿»è¯‘å®Œæˆ",
                "timestamp": time.time()
            }
            
            return {
                "success": True,
                "translated_text": translated_transcript.get("text", ""),
                "segments": translated_transcript.get("segments", []),
                "metadata": translated_transcript.get("translation_metadata", {})
            }
        except Exception as e:
            # æ›´æ–°é”™è¯¯çŠ¶æ€
            video_info["translation_progress"] = {
                "current": 0,
                "total": 0,
                "progress": 0.0,
                "message": f"ç¿»è¯‘å¤±è´¥: {str(e)}",
                "timestamp": time.time()
            }
            return {"error": f"ç¿»è¯‘å¤±è´¥: {str(e)}"}
    
    def build_vector_index(self, video_id):
        """
        ä¸ºè§†é¢‘å†…å®¹æ„å»ºå‘é‡ç´¢å¼•å’ŒBM25ç´¢å¼•
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.vector_store or not self.bm25_retriever:
            return {"error": "æ£€ç´¢å™¨æœªåˆå§‹åŒ–"}
        
        try:
            transcript = video_info["transcript"]
            
            # å‡†å¤‡æ–‡æ¡£æ•°æ®
            documents = []
            for segment in transcript.get("segments", []):
                doc = {
                    "text": segment["text"],
                    "start": segment["start"],
                    "end": segment["end"],
                    "video_id": video_id
                }
                documents.append(doc)
            
            # æ„å»ºå‘é‡ç´¢å¼•
            self.vector_store.clear()
            self.vector_store.add_documents(documents, text_field="text")
            vector_index_path = f"data/vectors/{video_id}_vector_index.pkl"
            self.vector_store.save_index(vector_index_path)
            
            # æ„å»ºBM25ç´¢å¼•
            self.bm25_retriever.clear()
            self.bm25_retriever.add_documents(documents, text_field="text")
            bm25_index_path = f"data/vectors/{video_id}_bm25_index.pkl"
            self.bm25_retriever.save_index(bm25_index_path)
            
            # å¦‚æœæœ‰æ··åˆæ£€ç´¢å™¨ï¼Œä¹Ÿæ·»åŠ æ–‡æ¡£
            if self.hybrid_retriever:
                self.hybrid_retriever.clear()
                self.hybrid_retriever.add_documents(documents, text_field="text")
                hybrid_index_path = f"data/vectors/{video_id}_hybrid_index.pkl"
                self.hybrid_retriever.save_indexes(vector_index_path, bm25_index_path)
            
            video_info["vector_index_built"] = True
            video_info["vector_index_path"] = vector_index_path
            video_info["bm25_index_path"] = bm25_index_path
            
            return {
                "success": True,
                "document_count": len(documents),
                "vector_stats": self.vector_store.get_stats(),
                "bm25_stats": self.bm25_retriever.get_stats(),
                "message": f"æˆåŠŸæ„å»ºå‘é‡ç´¢å¼•å’ŒBM25ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ"
            }
        except Exception as e:
            return {"error": f"æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}"}
    
    def search_in_video(self, video_id, query, max_results=5, threshold=0.3, search_type="hybrid"):
        """
        æœç´¢è§†é¢‘å†…å®¹
        
        Args:
            video_id: è§†é¢‘ID
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            threshold: ç›¸å…³æ€§é˜ˆå€¼
            search_type: æœç´¢ç±»å‹ ("vector", "bm25", "hybrid")
        """
        if video_id not in video_data:
            return []
        
        video_info = video_data[video_id]
        
        if not video_info.get("vector_index_built"):
            # å¦‚æœæ²¡æœ‰æ„å»ºç´¢å¼•ï¼Œå…ˆå°è¯•æ„å»º
            if video_info.get("transcript"):
                self.build_vector_index(video_id)
            else:
                return [{"text": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆï¼Œæ— æ³•æœç´¢", "timestamp": 0.0, "score": 0.0, "type": "error"}]
        
        try:
            results = []
            
            # æ ¹æ®æœç´¢ç±»å‹æ‰§è¡Œä¸åŒçš„æœç´¢
            if search_type == "vector" and self.vector_store:
                # å‘é‡æœç´¢
                vector_results = self.vector_store.search(query, top_k=max_results, threshold=threshold)
                for result in vector_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["similarity"], 3),
                        "end": doc["end"],
                        "type": "vector",
                        "similarity": round(result["similarity"], 3)
                    })
            
            elif search_type == "bm25" and self.bm25_retriever:
                # BM25æœç´¢
                bm25_results = self.bm25_retriever.search(query, top_k=max_results, threshold=threshold)
                for result in bm25_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["score"], 3),
                        "end": doc["end"],
                        "type": "bm25",
                        "bm25_score": round(result["score"], 3)
                    })
            
            elif search_type == "hybrid" and self.hybrid_retriever:
                # æ··åˆæœç´¢
                hybrid_results = self.hybrid_retriever.search(query, top_k=max_results, threshold=threshold)
                for result in hybrid_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["score"], 3),
                        "end": doc["end"],
                        "type": "hybrid",
                        "vector_score": round(result.get("vector_score", 0), 3),
                        "bm25_score": round(result.get("bm25_score", 0), 3)
                    })
            
            else:
                return [{"text": f"æ£€ç´¢å™¨æœªåˆå§‹åŒ–æˆ–ä¸æ”¯æŒæœç´¢ç±»å‹: {search_type}", "timestamp": 0.0, "score": 0.0, "type": "error"}]
            
            return results
            
        except Exception as e:
            return [{"text": f"æœç´¢å¤±è´¥: {str(e)}", "timestamp": 0.0, "score": 0.0, "type": "error"}]
    
    def build_index_background(self, video_id):
        """åå°æ„å»ºå‘é‡ç´¢å¼•"""
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.vector_store or not self.bm25_retriever:
            return {"error": "æ£€ç´¢å™¨æœªåˆå§‹åŒ–"}
        
        try:
            transcript = video_info["transcript"]
            
            # å‡†å¤‡æ–‡æ¡£æ•°æ®
            documents = []
            for segment in transcript.get("segments", []):
                doc = {
                    "text": segment["text"],
                    "start": segment["start"],
                    "end": segment["end"],
                    "video_id": video_id
                }
                documents.append(doc)
            
            # æ„å»ºå‘é‡ç´¢å¼•
            self.vector_store.clear()
            self.vector_store.add_documents(documents, text_field="text")
            vector_index_path = f"data/vectors/{video_id}_vector_index.pkl"
            self.vector_store.save_index(vector_index_path)
            
            # æ„å»ºBM25ç´¢å¼•
            self.bm25_retriever.clear()
            self.bm25_retriever.add_documents(documents, text_field="text")
            bm25_index_path = f"data/vectors/{video_id}_bm25_index.pkl"
            self.bm25_retriever.save_index(bm25_index_path)
            
            # å¦‚æœæœ‰æ··åˆæ£€ç´¢å™¨ï¼Œä¹Ÿæ·»åŠ æ–‡æ¡£
            if self.hybrid_retriever:
                self.hybrid_retriever.clear()
                self.hybrid_retriever.add_documents(documents, text_field="text")
                hybrid_index_path = f"data/vectors/{video_id}_hybrid_index.pkl"
                self.hybrid_retriever.save_indexes(vector_index_path, bm25_index_path)
            
            video_info["vector_index_built"] = True
            video_info["vector_index_path"] = vector_index_path
            video_info["bm25_index_path"] = bm25_index_path
            video_info["index_building"] = False
            
            return {
                "success": True,
                "document_count": len(documents),
                "vector_stats": self.vector_store.get_stats(),
                "bm25_stats": self.bm25_retriever.get_stats(),
                "message": f"æˆåŠŸæ„å»ºå‘é‡ç´¢å¼•å’ŒBM25ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ"
            }
        except Exception as e:
            video_info["index_building"] = False
            return {"error": f"æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}"}
    
    def get_translation_progress(self, video_id):
        """è·å–ç¿»è¯‘è¿›åº¦"""
        if video_id not in video_data:
            return {
                "current": 0,
                "total": 0,
                "progress": 0.0,
                "message": "è§†é¢‘ä¸å­˜åœ¨",
                "timestamp": time.time()
            }
        
        video_info = video_data[video_id]
        return video_info.get("translation_progress", {
            "current": 0,
            "total": 0,
            "progress": 0.0,
            "message": "å°šæœªå¼€å§‹ç¿»è¯‘",
            "timestamp": time.time()
        })
    
    def translate_background(self, video_id, target_lang):
        """åå°ç¿»è¯‘å¤„ç†"""
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.translator:
            return {"error": "ç¿»è¯‘å™¨æœªåˆå§‹åŒ–"}
        
        try:
            # è®¾ç½®å½“å‰æ­£åœ¨ç¿»è¯‘çš„è§†é¢‘IDï¼Œç”¨äºè¿›åº¦å›è°ƒ
            self._current_translating_video_id = video_id
            
            # åˆå§‹åŒ–ç¿»è¯‘è¿›åº¦
            video_info["translation_progress"] = {
                "current": 0,
                "total": 0,
                "progress": 0.0,
                "message": "å‡†å¤‡ç¿»è¯‘...",
                "timestamp": time.time()
            }
            
            transcript = video_info["transcript"]
            translated_transcript = self.translator.translate_transcript(transcript, target_lang)
            
            # ä¿å­˜ç¿»è¯‘ç»“æœ
            video_info[f"translated_transcript_{target_lang}"] = translated_transcript
            video_info["translating"] = False
            
            # æ›´æ–°ç¿»è¯‘å®ŒæˆçŠ¶æ€
            video_info["translation_progress"] = {
                "current": 1,
                "total": 1,
                "progress": 1.0,
                "message": "ç¿»è¯‘å®Œæˆ",
                "timestamp": time.time()
            }
            
            return {
                "success": True,
                "translated_text": translated_transcript.get("text", ""),
                "segments": translated_transcript.get("segments", []),
                "metadata": translated_transcript.get("translation_metadata", {}),
                "message": "ç¿»è¯‘å®Œæˆ"
            }
        except Exception as e:
            video_info["translating"] = False
            # æ›´æ–°é”™è¯¯çŠ¶æ€
            video_info["translation_progress"] = {
                "current": 0,
                "total": 0,
                "progress": 0.0,
                "message": f"ç¿»è¯‘å¤±è´¥: {str(e)}",
                "timestamp": time.time()
            }
            return {"error": f"ç¿»è¯‘å¤±è´¥: {str(e)}"}
    
    def get_conversation_stats(self, video_id):
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        if video_id in self.conversation_chains:
            return self.conversation_chains[video_id].get_stats()
        return {}
    
    def clear_conversation(self, video_id):
        """æ¸…é™¤æŒ‡å®šè§†é¢‘çš„å¯¹è¯å†å²"""
        if video_id in self.conversation_chains:
            self.conversation_chains[video_id].clear_history()
            return True
        return False
    
    def get_conversation_history(self, video_id):
        """è·å–å¯¹è¯å†å²"""
        if video_id in self.conversation_chains:
            return self.conversation_chains[video_id].get_conversation_history()
        return []


# å…¨å±€åŠ©æ‰‹å®ä¾‹å­—å…¸ï¼Œæ”¯æŒä¸åŒé…ç½®
assistants = {}
default_assistant = VideoAssistant(cuda_enabled=True, whisper_model="base")

def get_assistant(cuda_enabled=True, whisper_model="base"):
    """è·å–æˆ–åˆ›å»ºæŒ‡å®šé…ç½®çš„åŠ©æ‰‹å®ä¾‹"""
    key = f"{cuda_enabled}_{whisper_model}"
    if key not in assistants:
        assistants[key] = VideoAssistant(cuda_enabled=cuda_enabled, whisper_model=whisper_model)
    return assistants[key]


# Gradioç•Œé¢å‡½æ•°
def create_video_qa_interface():
    """åˆ›å»ºè§†é¢‘é—®ç­”ç•Œé¢"""
    
    # å¤„ç†è§†é¢‘ä¸Šä¼ 
    def handle_upload(video_file, cuda_enabled, whisper_model):
        # è·å–æŒ‡å®šé…ç½®çš„åŠ©æ‰‹
        current_assistant = get_assistant(cuda_enabled, whisper_model)
        result = current_assistant.upload_and_process_video(video_file)
        
        if result["status"] == "error":
            return (
                gr.Warning(result["message"]),
                gr.Video(visible=False),
                gr.JSON(visible=False),
                gr.Textbox(visible=False),
                gr.Row(visible=False),
                gr.Textbox(visible=False),
                gr.Textbox(visible=False),  # è½¬å½•æ–‡æœ¬
                gr.Button(visible=False),  # ç¿»è¯‘æŒ‰é’®
                gr.Dropdown(visible=False),  # è¯­è¨€é€‰æ‹©
                gr.Textbox(visible=False),  # ç¿»è¯‘ç»“æœ
                gr.HTML(visible=False)  # ç¿»è¯‘è¿›åº¦æ¡
            )
        
        return (
            gr.Textbox(value=result["message"], visible=True),
            gr.Video(value=video_file, visible=True),
            gr.JSON(value={"video_id": result["video_id"], "filename": result["filename"]}, visible=True),
            gr.Textbox(value="æ­£åœ¨å¤„ç†è§†é¢‘...", visible=True),
            gr.Row(visible=True),  # æ˜¾ç¤ºå¤„ç†æ—¥å¿—åŒºåŸŸ
            gr.Textbox(value=f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¤„ç†: {result['filename']}", visible=True),
            gr.HTML(value=f"<div style='width:100%; background-color:#e6f3ff; border-radius:5px; padding:5px; text-align:center;'>å¤„ç†è¿›åº¦: 0%</div>", visible=True),
            gr.Textbox(visible=False),  # éšè—è½¬å½•æ–‡æœ¬
            gr.Button(visible=False),  # éšè—ç¿»è¯‘æŒ‰é’®
            gr.Dropdown(visible=False),  # éšè—è¯­è¨€é€‰æ‹©
            gr.Textbox(visible=False),  # éšè—ç¿»è¯‘ç»“æœ
            gr.HTML(visible=False)  # éšè—ç¿»è¯‘è¿›åº¦æ¡
        )
    
    # æ›´æ–°å¤„ç†è¿›åº¦
    def update_progress(video_info):
        if not video_info or "video_id" not in video_info:
            return (
                "", 
                gr.Textbox(visible=False), 
                gr.Button(visible=False), 
                gr.Dropdown(visible=False), 
                gr.Textbox(visible=False),  # ç¿»è¯‘ç»“æœåŒºåŸŸ
                gr.Textbox(visible=False),
                gr.Textbox(value="ç­‰å¾…ä¸Šä¼ è§†é¢‘...", visible=True),
                gr.HTML(value="<div style='width:100%; background-color:#f0f0f0; border-radius:5px; padding:5px; text-align:center;'>ç­‰å¾…å¤„ç†...</div>", visible=False),
                gr.HTML(visible=False),  # ç¿»è¯‘è¿›åº¦æ¡
                gr.Textbox(visible=False)  # ç´¢å¼•çŠ¶æ€
            )
        
        video_id = video_info["video_id"]
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        progress_info = current_assistant.get_processing_progress(video_id)
        
        log_text = "\n".join(progress_info["log_messages"])
        progress_percent = int(progress_info["progress"] * 100)
        
        if progress_info["status"] == "completed":
            # å¤„ç†å®Œæˆï¼Œæ›´æ–°è½¬å½•æ˜¾ç¤º
            video_info_data = current_assistant.get_video_info(video_id)
            transcript = video_info_data.get("transcript", {}).get("text", "")
            
            # è‡ªåŠ¨æ„å»ºç´¢å¼•
            index_status, _ = auto_build_index(f"{video_id}: {video_info_data.get('filename', 'Unknown')}")
            
            return (
                log_text,
                gr.Textbox(value=transcript, visible=True),
                gr.Button(visible=True),  # æ˜¾ç¤ºç¿»è¯‘æŒ‰é’®
                gr.Dropdown(visible=True),  # æ˜¾ç¤ºè¯­è¨€é€‰æ‹©
                gr.Textbox(visible=True),  # æ˜¾ç¤ºç¿»è¯‘ç»“æœåŒºåŸŸ
                gr.Textbox(value="âœ… å¤„ç†å®Œæˆï¼ç°åœ¨å¯ä»¥è¿›è¡Œç¿»è¯‘å’Œå†…å®¹æœç´¢", visible=True),
                gr.HTML(value=f"<div style='width:100%; background-color:#d4edda; border-radius:5px; padding:5px; text-align:center;'>âœ… å¤„ç†å®Œæˆï¼</div>", visible=True),
                gr.HTML(visible=False),  # éšè—ç¿»è¯‘è¿›åº¦æ¡
                gr.Textbox(value=index_status, visible=True)  # æ˜¾ç¤ºç´¢å¼•çŠ¶æ€
            )
        
        return (
            log_text,
            gr.Textbox(visible=False),
            gr.Button(visible=False),
            gr.Dropdown(visible=False),
            gr.Textbox(visible=False),  # ç¿»è¯‘ç»“æœåŒºåŸŸ
            gr.Textbox(visible=False),
            gr.Textbox(value=f"â³ {progress_info['current_step']} ({progress_percent}%)", visible=True),
            gr.HTML(value=f"<div style='width:100%; background-color:#e6f3ff; border-radius:5px; padding:5px; text-align:center;'>â³ {progress_info['current_step']} ({progress_percent}%)</div>", visible=True),
            gr.HTML(visible=False),  # éšè—ç¿»è¯‘è¿›åº¦æ¡
            gr.Textbox(visible=False)  # ç´¢å¼•çŠ¶æ€
        )
    
    # å¤„ç†é—®ç­”
    def handle_question(question, history, video_selector):
        if not question.strip():
            return "", history
        
        if not video_selector:
            # æ·»åŠ é”™è¯¯æ¶ˆæ¯åˆ°å†å²è®°å½•
            history.append({"role": "user", "content": question})
            history.append({"role": "assistant", "content": "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘"})
            return "", history
        
        video_id = video_selector.split(":")[0].strip()  # å‡è®¾æ ¼å¼ä¸º "video_id: filename"
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        # è°ƒç”¨å¯¹è¯åŠŸèƒ½
        answer, updated_history = current_assistant.chat_with_video(video_id, question, history)
        
        # ç¡®ä¿å†å²è®°å½•æ ¼å¼æ­£ç¡®
        if not isinstance(updated_history, list):
            updated_history = []
        
        # å¦‚æœå†å²è®°å½•æ˜¯å…ƒç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        if updated_history and isinstance(updated_history[0], tuple):
            formatted_history = []
            for user_msg, assistant_msg in updated_history:
                formatted_history.append({"role": "user", "content": user_msg})
                formatted_history.append({"role": "assistant", "content": assistant_msg})
            updated_history = formatted_history
        
        return "", updated_history
    
    # å¤„ç†æœç´¢
    def handle_search(query, video_selector, search_type="hybrid"):
        if not query.strip() or not video_selector:
            return []
        
        video_id = video_selector.split(":")[0].strip()
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        results = current_assistant.search_in_video(video_id, query, search_type=search_type)
        
        formatted_results = []
        for r in results:
            if r["type"] == "vector":
                formatted = f"[{r['timestamp']:.2f}s] [å‘é‡ç›¸ä¼¼åº¦: {r['score']:.3f}] {r['text']}"
            elif r["type"] == "bm25":
                formatted = f"[{r['timestamp']:.2f}s] [BM25åˆ†æ•°: {r['score']:.3f}] {r['text']}"
            elif r["type"] == "hybrid":
                formatted = f"[{r['timestamp']:.2f}s] [æ··åˆåˆ†æ•°: {r['score']:.3f}] [å‘é‡: {r.get('vector_score', 0):.3f}] [BM25: {r.get('bm25_score', 0):.3f}] {r['text']}"
            else:
                formatted = f"[é”™è¯¯] {r['text']}"
            
            formatted_results.append(formatted)
        
        return formatted_results
    
    # å¤„ç†ç¿»è¯‘
    def handle_translate(video_info, target_lang):
        if not video_info or "video_id" not in video_info:
            return "è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†è§†é¢‘", gr.Textbox(visible=False), gr.HTML(visible=False), gr.HTML(visible=False)
        
        video_id = video_info["video_id"]
        
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        if video_id not in globals()['video_data']:
            return "è§†é¢‘ä¸å­˜åœ¨", gr.Textbox(visible=False), gr.HTML(visible=False), gr.HTML(visible=False)
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        # æ£€æŸ¥è½¬å½•æ˜¯å¦å®Œæˆ
        if not video_data[video_id].get("transcript"):
            return "è§†é¢‘å°šæœªè½¬å½•å®Œæˆï¼Œæ— æ³•ç¿»è¯‘", gr.Textbox(visible=False), gr.HTML(visible=False), gr.HTML(visible=False)
        
        # è®¾ç½®ç¿»è¯‘çŠ¶æ€
        video_data[video_id]["translating"] = True
        
        # å®é™…æ‰§è¡Œç¿»è¯‘
        try:
            result = current_assistant.translate_transcript(video_id, target_lang)
            
            if "error" in result:
                video_data[video_id]["translating"] = False
                return result["error"], gr.Textbox(visible=False), gr.HTML(visible=False), gr.HTML(visible=False)
            
            # ç¿»è¯‘æˆåŠŸ
            translated_text = result.get("translated_text", "")
            video_data[video_id]["translating"] = False
            return (
                "âœ… ç¿»è¯‘å®Œæˆ", 
                gr.Textbox(value=translated_text, visible=True),
                gr.HTML(value="<div style='width:100%; background-color:#d4edda; border-radius:5px; padding:5px; text-align:center;'>âœ… ç¿»è¯‘å®Œæˆ</div>", visible=True),
                gr.HTML(visible=False)  # éšè—è¿›åº¦æ¡
            )
            
        except Exception as e:
            video_data[video_id]["translating"] = False
            return f"ç¿»è¯‘å¤±è´¥: {str(e)}", gr.Textbox(visible=False), gr.HTML(visible=False), gr.HTML(visible=False)
    
    # æ›´æ–°ç¿»è¯‘è¿›åº¦
    def update_translation_progress(video_info):
        if not video_info or "video_id" not in video_info:
            return gr.HTML(visible=False)
        
        video_id = video_info["video_id"]
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç¿»è¯‘
        if video_id not in globals()['video_data'] or not globals()['video_data'][video_id].get("translating", False):
            return gr.HTML(visible=False)
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        # è·å–ç¿»è¯‘è¿›åº¦
        progress_info = current_assistant.get_translation_progress(video_id)
        progress_percent = int(progress_info["progress"] * 100)
        message = progress_info["message"]
        
        # æ„å»ºè¿›åº¦æ¡HTML
        progress_html = f"""
        <div style='width:100%; background-color:#f8f9fa; border-radius:5px; padding:10px; margin:10px 0;'>
            <div style='display: flex; justify-content: space-between; margin-bottom: 5px;'>
                <span>ç¿»è¯‘è¿›åº¦</span>
                <span>{progress_percent}%</span>
            </div>
            <div style='width:100%; background-color:#e9ecef; border-radius:3px; overflow: hidden;'>
                <div style='width:{progress_percent}%; background-color:#007bff; height:20px; transition: width 0.3s;'></div>
            </div>
            <div style='margin-top: 5px; font-size: 12px; color:#6c757d;'>
                {message}
            </div>
        </div>
        """
        
        return gr.HTML(value=progress_html, visible=True)
    
    # æ„å»ºå‘é‡ç´¢å¼•
    def handle_build_index(video_selector):
        if not video_selector:
            return "è¯·å…ˆé€‰æ‹©è§†é¢‘", gr.Textbox(visible=False), gr.HTML(visible=False)
        
        video_id = video_selector.split(":")[0].strip()
        
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        if video_id not in globals()['video_data']:
            return "è§†é¢‘ä¸å­˜åœ¨", gr.Textbox(visible=False), gr.HTML(visible=False)
        
        # æ£€æŸ¥è½¬å½•æ˜¯å¦å®Œæˆ
        if not globals()['video_data'][video_id].get("transcript"):
            return "è§†é¢‘å°šæœªè½¬å½•å®Œæˆï¼Œæ— æ³•æ„å»ºç´¢å¼•", gr.Textbox(visible=False), gr.HTML(visible=False)
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
            config = globals()['video_data'][video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        # è®¾ç½®æ„å»ºçŠ¶æ€
        globals()['video_data'][video_id]["index_building"] = True

        # å®é™…æ‰§è¡Œæ„å»ºç´¢å¼•
        try:
            result = current_assistant.build_index_background(video_id)
            if "error" in result:
                globals()['video_data'][video_id]["index_building"] = False
                return f"æ„å»ºå¤±è´¥: {result['error']}", gr.Textbox(visible=False), gr.HTML(visible=False)
            else:
                globals()['video_data'][video_id]["index_building"] = False
                return result.get("message", "ç´¢å¼•æ„å»ºå®Œæˆ"), gr.Textbox(visible=False), gr.HTML(value=f"<div style='width:100%; background-color:#d4edda; border-radius:5px; padding:5px; text-align:center;'>âœ… {result.get('message', 'ç´¢å¼•æ„å»ºå®Œæˆ')}</div>", visible=True)
        except Exception as e:
            globals()['video_data'][video_id]["index_building"] = False
            return f"æ„å»ºå¤±è´¥: {str(e)}", gr.Textbox(visible=False), gr.HTML(visible=False)
    
    # å¼€å§‹æ–°å¯¹è¯
    def start_new_chat(video_selector):
        """å¼€å§‹æ–°å¯¹è¯"""
        if video_selector:
            video_id = video_selector.split(":")[0].strip()
            
            # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
            if video_id in globals()['video_data'] and "assistant_config" in globals()['video_data'][video_id]:
                config = globals()['video_data'][video_id]["assistant_config"]
                current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
            else:
                current_assistant = default_assistant
            
            current_assistant.clear_conversation(video_id)
        return [], ""
    
    # è‡ªåŠ¨æ„å»ºç´¢å¼•å‡½æ•°
    def auto_build_index(video_selector):
        """è‡ªåŠ¨ä¸ºé€‰ä¸­çš„è§†é¢‘æ„å»ºç´¢å¼•"""
        if not video_selector:
            return "", gr.HTML(visible=False)
        
        video_id = video_selector.split(":")[0].strip()
        
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        if video_id not in globals()['video_data']:
            return "", gr.HTML(visible=False)
        
        # æ£€æŸ¥è½¬å½•æ˜¯å¦å®Œæˆ
        if not globals()['video_data'][video_id].get("transcript"):
            return "", gr.HTML(visible=False)
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²ç»æ„å»º
        if globals()['video_data'][video_id].get("vector_index_built", False):
            return "ç´¢å¼•å·²å­˜åœ¨", gr.HTML(visible=False)
        
        # è®¾ç½®æ„å»ºçŠ¶æ€
        globals()['video_data'][video_id]["index_building"] = True
        
        # è·å–å½“å‰è§†é¢‘ä½¿ç”¨çš„åŠ©æ‰‹é…ç½®
        if video_id in video_data and "assistant_config" in video_data[video_id]:
            config = video_data[video_id]["assistant_config"]
            current_assistant = get_assistant(config["cuda_enabled"], config["whisper_model"])
        else:
            current_assistant = default_assistant
        
        # å®é™…æ‰§è¡Œæ„å»ºç´¢å¼•
        try:
            result = current_assistant.build_index_background(video_id)
            if "error" in result:
                video_data[video_id]["index_building"] = False
                return f"æ„å»ºå¤±è´¥: {result['error']}", gr.HTML(visible=False)
            else:
                globals()['video_data'][video_id]["index_building"] = False
                return result.get("message", "ç´¢å¼•æ„å»ºå®Œæˆ"), gr.HTML(visible=False)
        except Exception as e:
            globals()['video_data'][video_id]["index_building"] = False
            return f"æ„å»ºå¤±è´¥: {str(e)}", gr.HTML(visible=False)
    
    # æ›´æ–°è§†é¢‘é€‰æ‹©å™¨
    def update_video_selector():
        videos = default_assistant.get_video_list()
        choices = [f"{v['video_id']}: {v['filename']}" for v in videos]
        return gr.Dropdown(choices=choices, value=choices[0] if choices else None)
    
    # åˆ›å»ºç•Œé¢
    with gr.Blocks(title="è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹", css="""
    .scrollable-textbox textarea {
        overflow-y: scroll !important;
        max-height: 300px !important;
    }
    """) as demo:
        gr.Markdown("# ğŸ¥ è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
        gr.Markdown("ä¸Šä¼ è§†é¢‘ï¼Œè¿›è¡Œæ™ºèƒ½é—®ç­”")
        
        with gr.Tabs():
            # è§†é¢‘ä¸Šä¼ å’Œç®¡ç†æ ‡ç­¾é¡µ
            with gr.TabItem("è§†é¢‘ç®¡ç†"):
                upload_status = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€", visible=False)

                with gr.Row():
                    with gr.Column(scale=1):
                        video_input = gr.File(
                            label="ä¸Šä¼ è§†é¢‘",
                            file_types=[".mp4", ".avi", ".mov", ".mkv"],
                            type="filepath"
                        )
                        
                        # å¤„ç†é€‰é¡¹
                        with gr.Accordion("å¤„ç†é€‰é¡¹", open=True):
                            cuda_enabled = gr.Checkbox(
                                label="å¯ç”¨CUDAåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰",
                                value=True,
                                info="ä½¿ç”¨GPUåŠ é€Ÿå¤„ç†ï¼Œéœ€è¦NVIDIAæ˜¾å¡å’Œæ”¯æŒCUDA"
                            )
                            
                            whisper_model = gr.Dropdown(
                                choices=[
                                    ("tiny (75MB, æœ€å¿«)", "tiny"),
                                    ("base (142MB, å¹³è¡¡)", "base"),
                                    ("small (466MB, è¾ƒå‡†ç¡®)", "small"),
                                    ("medium (1.5GB, å¾ˆå‡†ç¡®)", "medium"),
                                    ("large (2.9GB, æœ€å‡†ç¡®)", "large")
                                ],
                                value="base",
                                label="Whisperæ¨¡å‹é€‰æ‹©",
                                info="æ›´å¤§çš„æ¨¡å‹æ›´å‡†ç¡®ä½†éœ€è¦æ›´å¤šæ—¶é—´å’Œèµ„æº"
                            )
                        
                        upload_btn = gr.Button("ä¸Šä¼ å¹¶å¤„ç†è§†é¢‘", variant="primary")

                        # å¤„ç†æ—¥å¿—å’Œè¿›åº¦ - ç§»åŠ¨åˆ°ä¸Šä¼ åˆ—
                        progress_html = gr.HTML(
                            value="<div style='width:100%; background-color:#f0f0f0; border-radius:5px; padding:5px; text-align:center;'>ç­‰å¾…å¤„ç†...</div>",
                            visible=False
                        )
                        processing_log = gr.Textbox(
                            label="å¤„ç†æ—¥å¿—",
                            lines=10,
                            interactive=False,
                            max_lines=25,
                            show_label=True,
                            visible=False
                        )

                    with gr.Column(scale=2):
                        video_player = gr.Video(label="è§†é¢‘é¢„è§ˆ", visible=False)
                        video_info = gr.JSON(label="è§†é¢‘ä¿¡æ¯", visible=False)
                        processing_status = gr.Textbox(label="å¤„ç†çŠ¶æ€", visible=False)
                
                # è§†é¢‘å†…å®¹å±•ç¤º
                with gr.Accordion("è§†é¢‘å†…å®¹åˆ†æ", open=False):
                    transcript_display = gr.Textbox(
                        label="è½¬å½•æ–‡æœ¬",
                        lines=10,
                        interactive=False,
                        visible=False,
                        max_lines=30,
                        elem_classes="scrollable-textbox"
                    )
                    
                    # ç¿»è¯‘åŠŸèƒ½
                    with gr.Row():
                        translate_btn = gr.Button("ç¿»è¯‘æ–‡æœ¬", variant="secondary", visible=False)
                        target_lang = gr.Dropdown(
                            choices=["è¯·é€‰æ‹©è¯­è¨€", "English", "ä¸­æ–‡"],  # ç¬¬ä¸€ä¸ªé€‰é¡¹æ˜¯æç¤º
                            value="è¯·é€‰æ‹©è¯­è¨€",  # é»˜è®¤æ˜¾ç¤ºæç¤º
                            label="",  # å»æ‰æ ‡ç­¾
                            show_label=False,
                            visible=False
                        )
                    
                    translated_display = gr.Textbox(
                        label="ç¿»è¯‘ç»“æœ",
                        lines=10,
                        interactive=False,
                        visible=False,
                        max_lines=30,
                        elem_classes="scrollable-textbox"
                    )
                    
                    # ç¿»è¯‘è¿›åº¦
                    translate_progress_html = gr.HTML(
                        value="<div style='width:100%; background-color:#f0f0f0; border-radius:5px; padding:5px; text-align:center;'>ç­‰å¾…ç¿»è¯‘...</div>",
                        visible=False
                    )
                    
                    # ç¿»è¯‘è¿›åº¦æ¡
                    translate_progress_bar = gr.HTML(
                        visible=False
                    )
                    

            
            # æ™ºèƒ½é—®ç­”æ ‡ç­¾é¡µ
            with gr.TabItem("æ™ºèƒ½é—®ç­”"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # è§†é¢‘é€‰æ‹©
                        video_selector = gr.Dropdown(
                            label="é€‰æ‹©è§†é¢‘",
                            choices=[],
                            interactive=True
                        )
                        refresh_btn = gr.Button("åˆ·æ–°è§†é¢‘åˆ—è¡¨", size="sm")
                        
                        # æœç´¢åŠŸèƒ½
                        with gr.Accordion("å†…å®¹æœç´¢", open=False):
                            # ç´¢å¼•çŠ¶æ€ï¼ˆéšè—ï¼‰
                            index_status = gr.Textbox(label="ç´¢å¼•çŠ¶æ€", interactive=False, lines=2, visible=False)
                            index_progress_html = gr.HTML(
                        value="<div style='width:100%; background-color:#f0f0f0; border-radius:5px; padding:5px; text-align:center;'>ç­‰å¾…æ„å»ºç´¢å¼•...</div>",
                        visible=False
                    )
                            
                            # æœç´¢ç±»å‹é€‰æ‹©
                            search_type = gr.Radio(
                                choices=[
                                    ("æ··åˆæ£€ç´¢ (æ¨è)", "hybrid"),
                                    ("å‘é‡æ£€ç´¢", "vector"),
                                    ("å…³é”®è¯æ£€ç´¢ (BM25)", "bm25")
                                ],
                                value="hybrid",
                                label="æœç´¢ç±»å‹",
                                info="æ··åˆæ£€ç´¢ç»“åˆäº†è¯­ä¹‰ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…"
                            )
                            
                            # æœç´¢åŠŸèƒ½
                            search_query = gr.Textbox(label="æœç´¢å†…å®¹")
                            search_btn = gr.Button("æœç´¢")
                            search_results = gr.List(label="æœç´¢ç»“æœ")
                        
                        # æ–°å¯¹è¯æŒ‰é’®
                        new_chat_btn = gr.Button("å¼€å§‹æ–°å¯¹è¯", variant="secondary")
                    
                    with gr.Column(scale=2):
                        # èŠå¤©ç•Œé¢
                        chatbot = gr.Chatbot(
                            label="å¯¹è¯è®°å½•",
                            height=500
                        )
                        
                        with gr.Row():
                            question_input = gr.Textbox(
                                label="è¾“å…¥é—®é¢˜",
                                placeholder="è¯·è¾“å…¥å…³äºè§†é¢‘çš„é—®é¢˜...",
                                lines=2,
                                scale=4
                            )
                            send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                        
                        # å¿«æ·é—®é¢˜å»ºè®®
                        with gr.Accordion("å¿«æ·é—®é¢˜", open=False):
                            quick_questions = [
                                "è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                                "è§†é¢‘ä¸­æåˆ°äº†å“ªäº›å…³é”®ç‚¹ï¼Ÿ",
                                "èƒ½æ€»ç»“ä¸€ä¸‹è§†é¢‘çš„æ ¸å¿ƒè§‚ç‚¹å—ï¼Ÿ",
                                "è§†é¢‘ä¸­çš„ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ"
                            ]
                            
                            for i, question in enumerate(quick_questions):
                                gr.Button(question, size="sm").click(
                                    lambda q=question: q,
                                    outputs=question_input
                                )
        
        # äº‹ä»¶ç»‘å®š
        upload_btn.click(
            handle_upload,
            inputs=[video_input, cuda_enabled, whisper_model],
            outputs=[upload_status, video_player, video_info, processing_status, processing_log, progress_html, transcript_display, translate_btn, target_lang, translated_display, translate_progress_bar]
        )
        
        # å®šæ—¶æ›´æ–°å¤„ç†è¿›åº¦ - ä½¿ç”¨Timerç»„ä»¶æ›¿ä»£
        progress_timer = gr.Timer(2)  # æ¯2ç§’è§¦å‘ä¸€æ¬¡
        progress_timer.tick(
            update_progress,
            inputs=[video_info],
            outputs=[processing_log, transcript_display, translate_btn, target_lang, translated_display, processing_status, progress_html, translate_progress_bar, index_status]
        )
        
        # å®šæ—¶æ£€æŸ¥ç¿»è¯‘å’Œç´¢å¼•æ„å»ºè¿›åº¦
        def check_background_tasks(video_info):
            if not video_info or "video_id" not in video_info:
                return gr.HTML(visible=False), gr.HTML(visible=False)
            
            video_id = video_info["video_id"]
            
            # æ£€æŸ¥ç¿»è¯‘è¿›åº¦
            if video_id in video_data and video_data[video_id].get("translating", False):
                # æ¨¡æ‹Ÿç¿»è¯‘è¿›åº¦
                return gr.HTML(value="<div style='width:100%; background-color:#fff3cd; border-radius:5px; padding:5px; text-align:center;'>â³ æ­£åœ¨ç¿»è¯‘...</div>", visible=True), gr.HTML(visible=False)
            
            # æ£€æŸ¥ç´¢å¼•æ„å»ºè¿›åº¦
            if video_id in video_data and video_data[video_id].get("index_building", False):
                # æ¨¡æ‹Ÿç´¢å¼•æ„å»ºè¿›åº¦
                return gr.HTML(visible=False), gr.HTML(value="<div style='width:100%; background-color:#fff3cd; border-radius:5px; padding:5px; text-align:center;'>â³ æ­£åœ¨æ„å»ºç´¢å¼•...</div>", visible=True)
            
            return gr.HTML(visible=False), gr.HTML(visible=False)
        
        # æ·»åŠ åå°ä»»åŠ¡æ£€æŸ¥å®šæ—¶å™¨
        background_timer = gr.Timer(3)  # æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡
        background_timer.tick(
            check_background_tasks,
            inputs=[video_info],
            outputs=[translate_progress_html, index_progress_html]
        )
        
        # é—®ç­”äº‹ä»¶
        send_btn.click(
            handle_question,
            inputs=[question_input, chatbot, video_selector],
            outputs=[question_input, chatbot]
        )
        
        question_input.submit(
            handle_question,
            inputs=[question_input, chatbot, video_selector],
            outputs=[question_input, chatbot]
        )
        
        # æœç´¢äº‹ä»¶
        search_btn.click(
            handle_search,
            inputs=[search_query, video_selector, search_type],
            outputs=[search_results]
        )
        
        # ç¿»è¯‘äº‹ä»¶
        translate_btn.click(
            handle_translate,
            inputs=[video_info, target_lang],
            outputs=[processing_status, translated_display, translate_progress_html, translate_progress_bar]
        )
        
        # æ·»åŠ ç¿»è¯‘è¿›åº¦æ›´æ–°å®šæ—¶å™¨
        translation_progress_timer = gr.Timer(1)  # æ¯1ç§’æ›´æ–°ä¸€æ¬¡
        translation_progress_timer.tick(
            update_translation_progress,
            inputs=[video_info],
            outputs=[translate_progress_bar]
        )
        
        # æ„å»ºå‘é‡ç´¢å¼•äº‹ä»¶å·²ç§»é™¤ï¼Œæ”¹ä¸ºè‡ªåŠ¨æ„å»º
        
        # æ–°å¯¹è¯äº‹ä»¶
        new_chat_btn.click(
            start_new_chat,
            inputs=[video_selector],
            outputs=[chatbot, question_input]
        )
        
        # åˆ·æ–°è§†é¢‘åˆ—è¡¨
        def refresh_video_list():
            videos = default_assistant.get_video_list()
            choices = [f"{v['video_id']}: {v['filename']}" for v in videos]
            dropdown = gr.Dropdown(choices=choices, value=choices[0] if choices else None)
            
            # å¦‚æœæœ‰è§†é¢‘ï¼Œè‡ªåŠ¨ä¸ºç¬¬ä¸€ä¸ªè§†é¢‘æ„å»ºç´¢å¼•
            if choices:
                first_video = choices[0]
                index_status, _ = auto_build_index(first_video)
                return dropdown, gr.Textbox(value=index_status, visible=True)
            return dropdown, gr.Textbox(visible=False)
        
        refresh_btn.click(
            refresh_video_list,
            outputs=[video_selector, index_status]
        )
        
        # è§†é¢‘é€‰æ‹©æ—¶è‡ªåŠ¨æ„å»ºç´¢å¼•
        video_selector.change(
            lambda x: auto_build_index(x)[0],  # åªè¿”å›çŠ¶æ€æ–‡æœ¬
            inputs=[video_selector],
            outputs=[index_status]
        )
        
        # é¡µé¢åŠ è½½æ—¶æ›´æ–°è§†é¢‘åˆ—è¡¨
        demo.load(
            update_video_selector,
            outputs=[video_selector]
        )
    
    return demo


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_video_qa_interface()
    demo.launch(
        server_name="localhost",
        server_port=None,
        share=False,
        debug=True,
        theme=gr.themes.Soft()
    )