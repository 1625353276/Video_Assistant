#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹ - Webåº”ç”¨

æ•´åˆäº†è§†é¢‘ä¸Šä¼ ã€å¤„ç†ã€è½¬å½•ã€é—®ç­”ç­‰åŠŸèƒ½çš„å®Œæ•´Webåº”ç”¨
"""

import os
import sys
import time
import json
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import gradio as gr

os.environ['SSL_VERIFY'] = 'false'

# å°è¯•å¯¼å…¥åç«¯æ¨¡å—ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
MOCK_MODE = False
import_error = None

try:
    from modules.video.video_loader import VideoLoader
    print("âœ“ VideoLoader å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"VideoLoader å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.video.audio_extractor import AudioExtractor
    print("âœ“ AudioExtractor å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"AudioExtractor å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.speech.whisper_asr import WhisperASR
    print("âœ“ WhisperASR å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"WhisperASR å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.utils.file_manager import FileManager
    print("âœ“ FileManager å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    import_error = f"FileManager å¯¼å…¥å¤±è´¥: {e}"
    print(f"âœ— {import_error}")
    MOCK_MODE = True

try:
    from modules.text.translator import TextTranslator
    print("âœ“ TextTranslator å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— TextTranslator å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.vector_store import VectorStore
    print("âœ“ VectorStore å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— VectorStore å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.bm25_retriever import BM25Retriever
    print("âœ“ BM25Retriever å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— BM25Retriever å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

try:
    from modules.retrieval.hybrid_retriever import HybridRetriever
    print("âœ“ HybridRetriever å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— HybridRetriever å¯¼å…¥å¤±è´¥: {e}")
    MOCK_MODE = True

if MOCK_MODE:
    print(f"\nè­¦å‘Šï¼šå°†åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œ")
    print(f"é”™è¯¯åŸå› ï¼š{import_error}")
    print("è¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–ï¼špip install -r requirements.txt\n")
    
    # æ¨¡æ‹Ÿç±» - ä»…ç”¨äºå‰ç«¯å±•ç¤º
    class VideoLoader:
        def validate_video(self, video_path):
            import os
            file_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0
            return {
                "file_path": str(video_path),
                "file_name": os.path.basename(video_path),
                "file_size": file_size,
                "file_size_mb": round(file_size / (1024 * 1024), 2),
                "format": os.path.splitext(video_path)[1],
                "resolution": "1920x1080",
                "width": 1920,
                "height": 1080,
                "fps": 30.0,
                "frame_count": 9000,
                "duration": 300.0,
                "duration_formatted": "05:00",
                "aspect_ratio": 1.78,
                "validation_status": "passed"
            }
    
    class AudioExtractor:
        def extract_audio(self, video_path):
            import tempfile
            temp_dir = Path(tempfile.gettempdir()) / "ai_video_assistant"
            temp_dir.mkdir(parents=True, exist_ok=True)
            audio_path = temp_dir / f"{Path(video_path).stem}_extracted.wav"
            # åˆ›å»ºä¸€ä¸ªç©ºçš„éŸ³é¢‘æ–‡ä»¶ä½œä¸ºæ¨¡æ‹Ÿ
            audio_path.touch()
            return audio_path
    
    class WhisperASR:
        def __init__(self, model_size="base"):
            self.model_size = model_size
        
        def transcribe(self, audio_path):
            return {
                "audio_file": str(audio_path),
                "audio_file_name": Path(audio_path).name,
                "language": "zh",
                "language_probability": 0.9,
                "text": "è¿™æ˜¯æ¨¡æ‹Ÿçš„è½¬å½•æ–‡æœ¬ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯Whisperæ¨¡å‹ç”Ÿæˆçš„çœŸå®è½¬å½•ç»“æœã€‚",
                "segments": [
                    {
                        "id": 0,
                        "start": 0.0,
                        "end": 5.0,
                        "text": "è¿™æ˜¯ç¬¬ä¸€æ®µæ¨¡æ‹Ÿè½¬å½•æ–‡æœ¬ã€‚",
                        "confidence": 0.95,
                        "no_speech_prob": 0.01,
                        "words": []
                    },
                    {
                        "id": 1,
                        "start": 5.0,
                        "end": 10.0,
                        "text": "è¿™æ˜¯ç¬¬äºŒæ®µæ¨¡æ‹Ÿè½¬å½•æ–‡æœ¬ã€‚",
                        "confidence": 0.93,
                        "no_speech_prob": 0.02,
                        "words": []
                    }
                ],
                "words": [],
                "model_used": self.model_size,
                "device_used": "cpu",
                "total_duration": 10.0,
                "avg_confidence": 0.94,
                "speech_duration": 10.0,
                "speech_ratio": 1.0
            }
    
    class FileManager:
        def save_transcript_json(self, transcript_data, output_path):
            import json
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transcript_data, f, ensure_ascii=False, indent=2)
        
        def save_transcript_text(self, transcript_data, output_path):
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(transcript_data["text"])


# å…¨å±€å˜é‡å­˜å‚¨å¤„ç†çŠ¶æ€
processing_status = {}
video_data = {}


class VideoAssistant:
    """è§†é¢‘åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘åŠ©æ‰‹"""
        self.video_loader = VideoLoader()
        self.audio_extractor = AudioExtractor()
        self.whisper_asr = WhisperASR(model_size="base")
        self.file_manager = FileManager()
        
        # åˆå§‹åŒ–ç¿»è¯‘å™¨å’Œæ£€ç´¢å™¨
        if not MOCK_MODE:
            try:
                self.translator = TextTranslator(default_method="googletrans")
                print("âœ“ ç¿»è¯‘å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš  ç¿»è¯‘å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.translator = None
            
            try:
                self.vector_store = VectorStore(mirror_site="tuna")  # ä½¿ç”¨æ¸…åé•œåƒ
                print("âœ“ å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš  å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.vector_store = None
            
            try:
                self.bm25_retriever = BM25Retriever(language='auto')
                print("âœ“ BM25æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš  BM25æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                self.bm25_retriever = None
            
            # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
            if self.vector_store and self.bm25_retriever:
                try:
                    self.hybrid_retriever = HybridRetriever(
                        vector_store=self.vector_store,
                        bm25_retriever=self.bm25_retriever,
                        vector_weight=0.6,
                        bm25_weight=0.4,
                        fusion_method="weighted_average"
                    )
                    print("âœ“ æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    print(f"âš  æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: {e}")
                    self.hybrid_retriever = None
            else:
                self.hybrid_retriever = None
        else:
            self.translator = None
            self.vector_store = None
            self.bm25_retriever = None
            self.hybrid_retriever = None
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs("data/uploads", exist_ok=True)
        os.makedirs("data/transcripts", exist_ok=True)
        os.makedirs("data/temp", exist_ok=True)
        os.makedirs("data/vectors", exist_ok=True)
    
    def upload_and_process_video(self, video_file, user_id=None):
        """
        ä¸Šä¼ è§†é¢‘å¹¶è‡ªåŠ¨å¼€å§‹å¤„ç†
        """
        if video_file is None:
            return {
                "status": "error",
                "message": "è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶"
            }
        
        try:
            # ç”Ÿæˆå”¯ä¸€çš„è§†é¢‘ID
            video_path = Path(video_file)
            video_id = f"video_{int(time.time())}_{video_path.stem}"
            
            # å¤åˆ¶æ–‡ä»¶åˆ°ä¸Šä¼ ç›®å½•
            upload_path = Path(f"data/uploads/{video_id}{video_path.suffix}")
            import shutil
            shutil.copy2(video_file, upload_path)
            
            # éªŒè¯è§†é¢‘
            video_info = self.video_loader.validate_video(upload_path)
            
            # ä¿å­˜è§†é¢‘ä¿¡æ¯
            video_data[video_id] = {
                "video_id": video_id,
                "filename": video_path.name,
                "file_path": str(upload_path),
                "video_info": video_info,
                "status": "uploaded",
                "transcript": None,
                "summary": None,
                "upload_time": time.time()
            }
            
            # å¼€å§‹å¤„ç†
            processing_status[video_id] = {
                "progress": 0.0,
                "current_step": "å¼€å§‹å¤„ç†...",
                "log_messages": [f"[{time.strftime('%H:%M:%S')}] è§†é¢‘ä¸Šä¼ æˆåŠŸ: {video_path.name}"],
                "status": "processing"
            }
            
            return {
                "video_id": video_id,
                "filename": video_path.name,
                "status": "processing",
                "message": "è§†é¢‘ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹å¤„ç†..."
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}"
            }
    
    def get_processing_progress(self, video_id):
        """
        è·å–è§†é¢‘å¤„ç†è¿›åº¦
        """
        if video_id not in processing_status:
            return {
                "progress": 0.0,
                "current_step": "æœªæ‰¾åˆ°å¤„ç†ä»»åŠ¡",
                "log_messages": [],
                "status": "error"
            }
        
        # å¦‚æœè¿˜åœ¨å¤„ç†ä¸­ï¼Œç»§ç»­å¤„ç†
        if processing_status[video_id]["status"] == "processing":
            self._continue_processing(video_id)
        
        return processing_status[video_id]
    
    def _continue_processing(self, video_id):
        """
        ç»§ç»­å¤„ç†è§†é¢‘
        """
        if video_id not in video_data:
            return
        
        status = processing_status[video_id]
        video_info = video_data[video_id]
        
        try:
            progress = status["progress"]
            
            if progress < 0.2:
                # æå–éŸ³é¢‘
                status["current_step"] = "æå–éŸ³é¢‘ä¸­..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹æå–éŸ³é¢‘")
                status["progress"] = 0.2
                
                video_path = Path(video_info["file_path"])
                audio_path = self.audio_extractor.extract_audio(video_path)
                video_info["audio_path"] = str(audio_path)
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] éŸ³é¢‘æå–å®Œæˆ")
                
            elif progress < 0.7:
                # è¯­éŸ³è½¬æ–‡æœ¬
                status["current_step"] = "è¯­éŸ³è½¬æ–‡æœ¬ä¸­..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] å¼€å§‹è¯­éŸ³è½¬æ–‡æœ¬")
                status["progress"] = 0.7
                
                if "audio_path" in video_info:
                    audio_path = Path(video_info["audio_path"])
                    transcript_result = self.whisper_asr.transcribe(audio_path)
                    video_info["transcript"] = transcript_result
                    
                    # ä¿å­˜è½¬å½•ç»“æœ
                    transcript_path = Path(f"data/transcripts/{video_id}.json")
                    self.file_manager.save_transcript_json(transcript_result, transcript_path)
                    
                    status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] è¯­éŸ³è½¬æ–‡æœ¬å®Œæˆ")
                    
                    # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    if audio_path.exists():
                        audio_path.unlink()
                        
            elif progress < 0.9:
                # æ‘˜è¦ç”ŸæˆåŠŸèƒ½æœªå®ç°
                status["current_step"] = "æ‘˜è¦ç”ŸæˆåŠŸèƒ½æœªå®ç°..."
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] æ‘˜è¦ç”ŸæˆåŠŸèƒ½åœ¨modules/text/ä¸­æœªå®ç°")
                status["progress"] = 0.9
                
                # è·³è¿‡æ‘˜è¦ç”Ÿæˆ
                video_info["summary"] = "æ‘˜è¦ç”ŸæˆåŠŸèƒ½å°šæœªå®ç°"
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] è·³è¿‡æ‘˜è¦ç”Ÿæˆ")
                    
            else:
                # å¤„ç†å®Œæˆ
                status["progress"] = 1.0
                status["current_step"] = "å¤„ç†å®Œæˆ"
                status["status"] = "completed"
                status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] æ‰€æœ‰å¤„ç†ä»»åŠ¡å®Œæˆ")
                video_info["status"] = "completed"
                
        except Exception as e:
            status["status"] = "error"
            status["current_step"] = f"å¤„ç†å¤±è´¥: {str(e)}"
            status["log_messages"].append(f"[{time.strftime('%H:%M:%S')}] é”™è¯¯: {str(e)}")
    
    # æ³¨æ„ï¼šæ‘˜è¦ç”ŸæˆåŠŸèƒ½åœ¨modulesä¸­æœªå®ç°
    # éœ€è¦å®ç° modules/text/ ä¸­çš„ç›¸å…³æ¨¡å—
    
    def get_video_info(self, video_id):
        """
        è·å–è§†é¢‘ä¿¡æ¯
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        return video_data[video_id]
    
    def get_video_list(self, user_id=None):
        """
        è·å–è§†é¢‘åˆ—è¡¨
        """
        videos = []
        for video_id, info in video_data.items():
            if info["status"] == "completed":
                videos.append({
                    "video_id": video_id,
                    "filename": info["filename"],
                    "thumbnail": "",  # å¯ä»¥æ·»åŠ ç¼©ç•¥å›¾ç”Ÿæˆ
                    "upload_time": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(info["upload_time"]))
                })
        
        return videos
    
    def chat_with_video(self, video_id, question, chat_history, temperature=0.7):
        """
        åŸºäºè§†é¢‘å†…å®¹è¿›è¡Œé—®ç­”
        æ³¨æ„ï¼šé—®ç­”åŠŸèƒ½åœ¨modules/qa/ä¸­æœªå®ç°
        """
        if video_id not in video_data:
            return "è§†é¢‘ä¸å­˜åœ¨", chat_history
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return "è§†é¢‘å°šæœªå¤„ç†å®Œæˆï¼Œæ— æ³•è¿›è¡Œé—®ç­”", chat_history
        
        # é—®ç­”åŠŸèƒ½æœªå®ç°ï¼Œéœ€è¦å®ç° modules/qa/ ä¸­çš„ç›¸å…³æ¨¡å—
        return f"é—®ç­”åŠŸèƒ½å°šæœªå®ç°ã€‚é—®é¢˜ï¼š{question}\næ³¨æ„ï¼šéœ€è¦åœ¨modules/qa/ä¸­å®ç°conversation_chainç­‰æ¨¡å—", chat_history + [(question, f"é—®ç­”åŠŸèƒ½å°šæœªå®ç°ã€‚é—®é¢˜ï¼š{question}")]
    
    # æ³¨æ„ï¼šé—®ç­”åŠŸèƒ½åœ¨modules/qa/ä¸­æœªå®ç°
    # éœ€è¦å®ç° modules/qa/conversation_chain.py ç­‰æ¨¡å—
    
    def translate_transcript(self, video_id, target_lang):
        """
        ç¿»è¯‘è½¬å½•æ–‡æœ¬
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.translator:
            return {"error": "ç¿»è¯‘å™¨æœªåˆå§‹åŒ–"}
        
        try:
            transcript = video_info["transcript"]
            translated_transcript = self.translator.translate_transcript(transcript, target_lang)
            
            # ä¿å­˜ç¿»è¯‘ç»“æœ
            video_info[f"translated_transcript_{target_lang}"] = translated_transcript
            
            return {
                "success": True,
                "translated_text": translated_transcript.get("text", ""),
                "segments": translated_transcript.get("segments", []),
                "metadata": translated_transcript.get("translation_metadata", {})
            }
        except Exception as e:
            return {"error": f"ç¿»è¯‘å¤±è´¥: {str(e)}"}
    
    def build_vector_index(self, video_id):
        """
        ä¸ºè§†é¢‘å†…å®¹æ„å»ºå‘é‡ç´¢å¼•å’ŒBM25ç´¢å¼•
        """
        if video_id not in video_data:
            return {"error": "è§†é¢‘ä¸å­˜åœ¨"}
        
        video_info = video_data[video_id]
        
        if not video_info.get("transcript"):
            return {"error": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆ"}
        
        if not self.vector_store or not self.bm25_retriever:
            return {"error": "æ£€ç´¢å™¨æœªåˆå§‹åŒ–"}
        
        try:
            transcript = video_info["transcript"]
            
            # å‡†å¤‡æ–‡æ¡£æ•°æ®
            documents = []
            for segment in transcript.get("segments", []):
                doc = {
                    "text": segment["text"],
                    "start": segment["start"],
                    "end": segment["end"],
                    "video_id": video_id
                }
                documents.append(doc)
            
            # æ„å»ºå‘é‡ç´¢å¼•
            self.vector_store.clear()
            self.vector_store.add_documents(documents, text_field="text")
            vector_index_path = f"data/vectors/{video_id}_vector_index.pkl"
            self.vector_store.save_index(vector_index_path)
            
            # æ„å»ºBM25ç´¢å¼•
            self.bm25_retriever.clear()
            self.bm25_retriever.add_documents(documents, text_field="text")
            bm25_index_path = f"data/vectors/{video_id}_bm25_index.pkl"
            self.bm25_retriever.save_index(bm25_index_path)
            
            # å¦‚æœæœ‰æ··åˆæ£€ç´¢å™¨ï¼Œä¹Ÿæ·»åŠ æ–‡æ¡£
            if self.hybrid_retriever:
                self.hybrid_retriever.clear()
                self.hybrid_retriever.add_documents(documents, text_field="text")
                hybrid_index_path = f"data/vectors/{video_id}_hybrid_index.pkl"
                self.hybrid_retriever.save_indexes(vector_index_path, bm25_index_path)
            
            video_info["vector_index_built"] = True
            video_info["vector_index_path"] = vector_index_path
            video_info["bm25_index_path"] = bm25_index_path
            
            return {
                "success": True,
                "document_count": len(documents),
                "vector_stats": self.vector_store.get_stats(),
                "bm25_stats": self.bm25_retriever.get_stats(),
                "message": f"æˆåŠŸæ„å»ºå‘é‡ç´¢å¼•å’ŒBM25ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ"
            }
        except Exception as e:
            return {"error": f"æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}"}
    
    def search_in_video(self, video_id, query, max_results=5, threshold=0.3, search_type="hybrid"):
        """
        æœç´¢è§†é¢‘å†…å®¹
        
        Args:
            video_id: è§†é¢‘ID
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            threshold: ç›¸å…³æ€§é˜ˆå€¼
            search_type: æœç´¢ç±»å‹ ("vector", "bm25", "hybrid")
        """
        if video_id not in video_data:
            return []
        
        video_info = video_data[video_id]
        
        if not video_info.get("vector_index_built"):
            # å¦‚æœæ²¡æœ‰æ„å»ºç´¢å¼•ï¼Œå…ˆå°è¯•æ„å»º
            if video_info.get("transcript"):
                self.build_vector_index(video_id)
            else:
                return [{"text": "è§†é¢‘å°šæœªå¤„ç†å®Œæˆï¼Œæ— æ³•æœç´¢", "timestamp": 0.0, "score": 0.0, "type": "error"}]
        
        try:
            results = []
            
            # æ ¹æ®æœç´¢ç±»å‹æ‰§è¡Œä¸åŒçš„æœç´¢
            if search_type == "vector" and self.vector_store:
                # å‘é‡æœç´¢
                vector_results = self.vector_store.search(query, top_k=max_results, threshold=threshold)
                for result in vector_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["similarity"], 3),
                        "end": doc["end"],
                        "type": "vector",
                        "similarity": round(result["similarity"], 3)
                    })
            
            elif search_type == "bm25" and self.bm25_retriever:
                # BM25æœç´¢
                bm25_results = self.bm25_retriever.search(query, top_k=max_results, threshold=threshold)
                for result in bm25_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["score"], 3),
                        "end": doc["end"],
                        "type": "bm25",
                        "bm25_score": round(result["score"], 3)
                    })
            
            elif search_type == "hybrid" and self.hybrid_retriever:
                # æ··åˆæœç´¢
                hybrid_results = self.hybrid_retriever.search(query, top_k=max_results, threshold=threshold)
                for result in hybrid_results:
                    doc = result["document"]
                    results.append({
                        "text": doc["text"],
                        "timestamp": doc["start"],
                        "score": round(result["score"], 3),
                        "end": doc["end"],
                        "type": "hybrid",
                        "vector_score": round(result.get("vector_score", 0), 3),
                        "bm25_score": round(result.get("bm25_score", 0), 3)
                    })
            
            else:
                return [{"text": f"æ£€ç´¢å™¨æœªåˆå§‹åŒ–æˆ–ä¸æ”¯æŒæœç´¢ç±»å‹: {search_type}", "timestamp": 0.0, "score": 0.0, "type": "error"}]
            
            return results
            
        except Exception as e:
            return [{"text": f"æœç´¢å¤±è´¥: {str(e)}", "timestamp": 0.0, "score": 0.0, "type": "error"}]


# åˆ›å»ºå…¨å±€åŠ©æ‰‹å®ä¾‹
assistant = VideoAssistant()


# Gradioç•Œé¢å‡½æ•°
def create_video_qa_interface():
    """åˆ›å»ºè§†é¢‘é—®ç­”ç•Œé¢"""
    
    # å¤„ç†è§†é¢‘ä¸Šä¼ 
    def handle_upload(video_file):
        result = assistant.upload_and_process_video(video_file)
        
        if result["status"] == "error":
            return (
                gr.Warning(result["message"]),
                gr.Video(visible=False),
                gr.JSON(visible=False),
                gr.Textbox(visible=False),
                gr.Row(visible=False),
                gr.Textbox(visible=False)
            )
        
        return (
            gr.Textbox(value=result["message"], visible=True),
            gr.Video(value=video_file, visible=True),
            gr.JSON(value={"video_id": result["video_id"], "filename": result["filename"]}, visible=True),
            gr.Textbox(value="æ­£åœ¨å¤„ç†è§†é¢‘...", visible=True),
            gr.Row(visible=True),  # æ˜¾ç¤ºå¤„ç†æ—¥å¿—åŒºåŸŸ
            gr.Textbox(value=f"[{time.strftime('%H:%M:%S')}] å¼€å§‹å¤„ç†: {result['filename']}", visible=True)
        )
    
    # æ›´æ–°å¤„ç†è¿›åº¦
    def update_progress(video_info):
        if not video_info or "video_id" not in video_info:
            return (
                "", 
                gr.Textbox(visible=False), 
                gr.Button(visible=False), 
                gr.Dropdown(visible=False), 
                gr.Textbox(visible=False),  # ç¿»è¯‘ç»“æœåŒºåŸŸ
                gr.Textbox(visible=False),
                gr.Textbox(value="ç­‰å¾…ä¸Šä¼ è§†é¢‘...", visible=True)
            )
        
        video_id = video_info["video_id"]
        progress_info = assistant.get_processing_progress(video_id)
        
        log_text = "\n".join(progress_info["log_messages"])
        
        if progress_info["status"] == "completed":
            # å¤„ç†å®Œæˆï¼Œæ›´æ–°è½¬å½•å’Œæ‘˜è¦æ˜¾ç¤º
            video_data = assistant.get_video_info(video_id)
            transcript = video_data.get("transcript", {}).get("text", "")
            summary = video_data.get("summary", "")
            
            return (
                log_text,
                gr.Textbox(value=transcript, visible=True),
                gr.Button(visible=True),  # æ˜¾ç¤ºç¿»è¯‘æŒ‰é’®
                gr.Dropdown(visible=True),  # æ˜¾ç¤ºè¯­è¨€é€‰æ‹©
                gr.Textbox(visible=True),  # æ˜¾ç¤ºç¿»è¯‘ç»“æœåŒºåŸŸ
                gr.Textbox(value=summary, visible=True),
                gr.Textbox(value="å¤„ç†å®Œæˆï¼", visible=True)
            )
        
        return (
            log_text,
            gr.Textbox(visible=False),
            gr.Button(visible=False),
            gr.Dropdown(visible=False),
            gr.Textbox(visible=False),  # ç¿»è¯‘ç»“æœåŒºåŸŸ
            gr.Textbox(visible=False),
            gr.Textbox(value=progress_info["current_step"], visible=True)
        )
    
    # å¤„ç†é—®ç­”
    def handle_question(question, history, video_selector):
        if not question.strip():
            return "", history
        
        if not video_selector:
            return "", history + [(question, "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§†é¢‘")]
        
        video_id = video_selector.split(":")[0].strip()  # å‡è®¾æ ¼å¼ä¸º "video_id: filename"
        
        answer, updated_history = assistant.chat_with_video(video_id, question, history)
        
        return "", updated_history
    
    # å¤„ç†æœç´¢
    def handle_search(query, video_selector, search_type="hybrid"):
        if not query.strip() or not video_selector:
            return []
        
        video_id = video_selector.split(":")[0].strip()
        results = assistant.search_in_video(video_id, query, search_type=search_type)
        
        formatted_results = []
        for r in results:
            if r["type"] == "vector":
                formatted = f"[{r['timestamp']:.2f}s] [å‘é‡ç›¸ä¼¼åº¦: {r['score']:.3f}] {r['text']}"
            elif r["type"] == "bm25":
                formatted = f"[{r['timestamp']:.2f}s] [BM25åˆ†æ•°: {r['score']:.3f}] {r['text']}"
            elif r["type"] == "hybrid":
                formatted = f"[{r['timestamp']:.2f}s] [æ··åˆåˆ†æ•°: {r['score']:.3f}] [å‘é‡: {r.get('vector_score', 0):.3f}] [BM25: {r.get('bm25_score', 0):.3f}] {r['text']}"
            else:
                formatted = f"[é”™è¯¯] {r['text']}"
            
            formatted_results.append(formatted)
        
        return formatted_results
    
    # å¤„ç†ç¿»è¯‘
    def handle_translate(video_info, target_lang):
        if not video_info or "video_id" not in video_info:
            return "è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†è§†é¢‘", gr.Textbox(visible=False)
        
        video_id = video_info["video_id"]
        result = assistant.translate_transcript(video_id, target_lang)
        
        if "error" in result:
            return result["error"], gr.Textbox(visible=False)
        
        return "ç¿»è¯‘æˆåŠŸ", gr.Textbox(value=result["translated_text"], visible=True)
    
    # æ„å»ºå‘é‡ç´¢å¼•
    def handle_build_index(video_selector):
        if not video_selector:
            return "è¯·å…ˆé€‰æ‹©è§†é¢‘"
        
        video_id = video_selector.split(":")[0].strip()
        result = assistant.build_vector_index(video_id)
        
        if "error" in result:
            return result["error"]
        
        return result["message"]
    
    # å¼€å§‹æ–°å¯¹è¯
    def start_new_chat():
        return [], ""
    
    # æ›´æ–°è§†é¢‘é€‰æ‹©å™¨
    def update_video_selector():
        videos = assistant.get_video_list()
        choices = [f"{v['video_id']}: {v['filename']}" for v in videos]
        return gr.Dropdown(choices=choices, value=choices[0] if choices else None)
    
    # åˆ›å»ºç•Œé¢
    with gr.Blocks(title="è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹") as demo:
        gr.Markdown("# ğŸ¥ è§†é¢‘æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
        gr.Markdown("ä¸Šä¼ è§†é¢‘ï¼Œè·å–æ™ºèƒ½æ‘˜è¦ï¼Œè¿›è¡Œå¤šè½®é—®ç­”")
        
        with gr.Tabs():
            # è§†é¢‘ä¸Šä¼ å’Œç®¡ç†æ ‡ç­¾é¡µ
            with gr.TabItem("è§†é¢‘ç®¡ç†"):
                upload_status = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€", visible=False)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        video_input = gr.File(
                            label="ä¸Šä¼ è§†é¢‘",
                            file_types=[".mp4", ".avi", ".mov", ".mkv"],
                            type="filepath"
                        )
                        upload_btn = gr.Button("ä¸Šä¼ å¹¶å¤„ç†è§†é¢‘", variant="primary")
                        
                    with gr.Column(scale=2):
                        video_player = gr.Video(label="è§†é¢‘é¢„è§ˆ", visible=False)
                        video_info = gr.JSON(label="è§†é¢‘ä¿¡æ¯", visible=False)
                        processing_status = gr.Textbox(label="å¤„ç†çŠ¶æ€", visible=False)
                
                # å¤„ç†æ—¥å¿—å’Œè¿›åº¦
                with gr.Row(visible=False) as processing_row:
                    with gr.Column():
                        processing_log = gr.Textbox(
                            label="å¤„ç†æ—¥å¿—",
                            lines=10,
                            interactive=False,
                            max_lines=15,
                            show_label=True
                        )
                
                # è§†é¢‘å†…å®¹å±•ç¤º
                with gr.Accordion("è§†é¢‘å†…å®¹åˆ†æ", open=False):
                    transcript_display = gr.Textbox(
                        label="è½¬å½•æ–‡æœ¬",
                        lines=10,
                        interactive=False,
                        visible=False
                    )
                    
                    # ç¿»è¯‘åŠŸèƒ½
                    with gr.Row():
                        translate_btn = gr.Button("ç¿»è¯‘æ–‡æœ¬", variant="secondary", visible=False)
                        target_lang = gr.Dropdown(
                            choices=["en", "zh"],
                            value="en",
                            label="ç›®æ ‡è¯­è¨€",
                            visible=False
                        )
                    
                    translated_display = gr.Textbox(
                        label="ç¿»è¯‘ç»“æœ",
                        lines=10,
                        interactive=False,
                        visible=False
                    )
                    
                    summary_display = gr.Textbox(
                        label="è§†é¢‘æ‘˜è¦",
                        lines=5,
                        interactive=False,
                        visible=False
                    )
            
            # æ™ºèƒ½é—®ç­”æ ‡ç­¾é¡µ
            with gr.TabItem("æ™ºèƒ½é—®ç­”"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # è§†é¢‘é€‰æ‹©
                        video_selector = gr.Dropdown(
                            label="é€‰æ‹©è§†é¢‘",
                            choices=[],
                            interactive=True
                        )
                        refresh_btn = gr.Button("åˆ·æ–°è§†é¢‘åˆ—è¡¨", size="sm")
                        
                        # æœç´¢åŠŸèƒ½
                        with gr.Accordion("å†…å®¹æœç´¢", open=False):
                            # ç´¢å¼•æ„å»º
                            build_index_btn = gr.Button("æ„å»ºæ£€ç´¢ç´¢å¼•", variant="secondary", size="sm")
                            index_status = gr.Textbox(label="ç´¢å¼•çŠ¶æ€", interactive=False, lines=2)
                            
                            # æœç´¢ç±»å‹é€‰æ‹©
                            search_type = gr.Radio(
                                choices=[
                                    ("æ··åˆæ£€ç´¢ (æ¨è)", "hybrid"),
                                    ("å‘é‡æ£€ç´¢", "vector"),
                                    ("å…³é”®è¯æ£€ç´¢ (BM25)", "bm25")
                                ],
                                value="hybrid",
                                label="æœç´¢ç±»å‹",
                                info="æ··åˆæ£€ç´¢ç»“åˆäº†è¯­ä¹‰ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…"
                            )
                            
                            # æœç´¢åŠŸèƒ½
                            search_query = gr.Textbox(label="æœç´¢å†…å®¹")
                            search_btn = gr.Button("æœç´¢")
                            search_results = gr.List(label="æœç´¢ç»“æœ")
                        
                        # æ–°å¯¹è¯æŒ‰é’®
                        new_chat_btn = gr.Button("å¼€å§‹æ–°å¯¹è¯", variant="secondary")
                    
                    with gr.Column(scale=2):
                        # èŠå¤©ç•Œé¢
                        chatbot = gr.Chatbot(
                            label="å¯¹è¯è®°å½•",
                            height=500
                        )
                        
                        with gr.Row():
                            question_input = gr.Textbox(
                                label="è¾“å…¥é—®é¢˜",
                                placeholder="è¯·è¾“å…¥å…³äºè§†é¢‘çš„é—®é¢˜...",
                                lines=2,
                                scale=4
                            )
                            send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                        
                        # å¿«æ·é—®é¢˜å»ºè®®
                        with gr.Accordion("å¿«æ·é—®é¢˜", open=False):
                            quick_questions = [
                                "è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                                "è§†é¢‘ä¸­æåˆ°äº†å“ªäº›å…³é”®ç‚¹ï¼Ÿ",
                                "èƒ½æ€»ç»“ä¸€ä¸‹è§†é¢‘çš„æ ¸å¿ƒè§‚ç‚¹å—ï¼Ÿ",
                                "è§†é¢‘ä¸­çš„ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ"
                            ]
                            
                            for i, question in enumerate(quick_questions):
                                gr.Button(question, size="sm").click(
                                    lambda q=question: q,
                                    outputs=question_input
                                )
        
        # äº‹ä»¶ç»‘å®š
        upload_btn.click(
            handle_upload,
            inputs=[video_input],
            outputs=[upload_status, video_player, video_info, processing_status, processing_row, processing_log]
        )
        
        # å®šæ—¶æ›´æ–°å¤„ç†è¿›åº¦ - ä½¿ç”¨Timerç»„ä»¶æ›¿ä»£
        progress_timer = gr.Timer(2)  # æ¯2ç§’è§¦å‘ä¸€æ¬¡
        progress_timer.tick(
            update_progress,
            inputs=[video_info],
            outputs=[processing_log, transcript_display, translate_btn, target_lang, translated_display, summary_display, processing_status]
        )
        
        # é—®ç­”äº‹ä»¶
        send_btn.click(
            handle_question,
            inputs=[question_input, chatbot, video_selector],
            outputs=[question_input, chatbot]
        )
        
        question_input.submit(
            handle_question,
            inputs=[question_input, chatbot, video_selector],
            outputs=[question_input, chatbot]
        )
        
        # æœç´¢äº‹ä»¶
        search_btn.click(
            handle_search,
            inputs=[search_query, video_selector, search_type],
            outputs=[search_results]
        )
        
        # ç¿»è¯‘äº‹ä»¶
        translate_btn.click(
            handle_translate,
            inputs=[video_info, target_lang],
            outputs=[processing_status, translated_display]
        )
        
        # æ„å»ºå‘é‡ç´¢å¼•äº‹ä»¶
        build_index_btn.click(
            handle_build_index,
            inputs=[video_selector],
            outputs=[index_status]
        )
        
        # æ–°å¯¹è¯äº‹ä»¶
        new_chat_btn.click(
            start_new_chat,
            outputs=[chatbot, question_input]
        )
        
        # åˆ·æ–°è§†é¢‘åˆ—è¡¨
        refresh_btn.click(
            update_video_selector,
            outputs=[video_selector]
        )
        
        # é¡µé¢åŠ è½½æ—¶æ›´æ–°è§†é¢‘åˆ—è¡¨
        demo.load(
            update_video_selector,
            outputs=[video_selector]
        )
    
    return demo


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_video_qa_interface()
    demo.launch(
        server_name="localhost",
        server_port=7860,
        share=False,
        debug=True,
        theme=gr.themes.Soft()
    )