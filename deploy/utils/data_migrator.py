#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è¿ç§»å·¥å…·

å°†å…±äº«æ•°æ®ç›®å½•ä¸­çš„ç°æœ‰æ•°æ®è¿ç§»åˆ°ç”¨æˆ·éš”ç¦»çš„ç›®å½•ç»“æ„ä¸­
"""

import os
import json
import shutil
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self, base_data_dir: str = "data"):
        """
        åˆå§‹åŒ–æ•°æ®è¿ç§»å™¨
        
        Args:
            base_data_dir: åŸºç¡€æ•°æ®ç›®å½•
        """
        self.base_data_dir = Path(base_data_dir)
        self.shared_dirs = {
            "videos": self.base_data_dir / "raw_videos",
            "transcripts": self.base_data_dir / "transcripts", 
            "conversations": self.base_data_dir / "memory",
            "vectors": self.base_data_dir / "vectors",
            "cache": self.base_data_dir / "cache"
        }
        self.users_dir = self.base_data_dir / "users"
        self.migration_log = []
        
    def scan_shared_data(self) -> Dict[str, List[Dict]]:
        """
        æ‰«æå…±äº«æ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®
        
        Returns:
            Dict[str, List[Dict]]: å„ä¸ªç±»å‹çš„æ•°æ®åˆ—è¡¨
        """
        logger.info("å¼€å§‹æ‰«æå…±äº«æ•°æ®ç›®å½•...")
        
        shared_data = {
            "videos": [],
            "transcripts": [],
            "conversations": [],
            "vectors": []
        }
        
        # æ‰«æè§†é¢‘æ–‡ä»¶
        if self.shared_dirs["videos"].exists():
            for video_file in self.shared_dirs["videos"].glob("*"):
                if video_file.is_file() and video_file.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv', '.webm']:
                    stat = video_file.stat()
                    shared_data["videos"].append({
                        "path": str(video_file),
                        "filename": video_file.name,
                        "size": stat.st_size,
                        "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "md5": self._calculate_md5(video_file)
                    })
        
        # æ‰«æè½¬å½•æ–‡ä»¶
        if self.shared_dirs["transcripts"].exists():
            for transcript_file in self.shared_dirs["transcripts"].glob("*"):
                if transcript_file.is_file() and transcript_file.suffix.lower() in ['.json', '.txt', '.srt']:
                    stat = transcript_file.stat()
                    shared_data["transcripts"].append({
                        "path": str(transcript_file),
                        "filename": transcript_file.name,
                        "size": stat.st_size,
                        "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": transcript_file.suffix.lower()
                    })
        
        # æ‰«æå¯¹è¯å†å²
        if self.shared_dirs["conversations"].exists():
            for conv_file in self.shared_dirs["conversations"].glob("*"):
                if conv_file.is_file() and conv_file.suffix.lower() == '.json':
                    try:
                        with open(conv_file, 'r', encoding='utf-8') as f:
                            conv_data = json.load(f)
                        
                        # å°è¯•è¯†åˆ«å¯¹è¯æ‰€å±ç”¨æˆ·ï¼ˆå¦‚æœæœ‰ï¼‰
                        user_id = conv_data.get('user_id', 'unknown')
                        
                        shared_data["conversations"].append({
                            "path": str(conv_file),
                            "filename": conv_file.name,
                            "size": conv_file.stat().st_size,
                            "modified_time": datetime.fromtimestamp(conv_file.stat().st_mtime).isoformat(),
                            "user_id": user_id,
                            "data": conv_data
                        })
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–å¯¹è¯æ–‡ä»¶ {conv_file}: {e}")
        
        # æ‰«æå‘é‡ç´¢å¼•
        if self.shared_dirs["vectors"].exists():
            for vector_file in self.shared_dirs["vectors"].glob("*"):
                if vector_file.is_file():
                    stat = vector_file.stat()
                    shared_data["vectors"].append({
                        "path": str(vector_file),
                        "filename": vector_file.name,
                        "size": stat.st_size,
                        "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": "vector_index"
                    })
        
        logger.info(f"æ‰«æå®Œæˆï¼Œå‘ç°: {len(shared_data['videos'])} ä¸ªè§†é¢‘, "
                   f"{len(shared_data['transcripts'])} ä¸ªè½¬å½•æ–‡ä»¶, "
                   f"{len(shared_data['conversations'])} ä¸ªå¯¹è¯, "
                   f"{len(shared_data['vectors'])} ä¸ªå‘é‡æ–‡ä»¶")
        
        return shared_data
    
    def identify_user_ownership(self, shared_data: Dict[str, List[Dict]]) -> Dict[str, Dict]:
        """
        è¯†åˆ«æ•°æ®å½’å±ç”¨æˆ·
        
        Args:
            shared_data: å…±äº«æ•°æ®
            
        Returns:
            Dict[str, Dict]: ç”¨æˆ·æ•°æ®æ˜ å°„
        """
        logger.info("å¼€å§‹è¯†åˆ«æ•°æ®å½’å±...")
        
        user_data_map = {}
        
        # åˆ†æå¯¹è¯æ–‡ä»¶ä¸­çš„ç”¨æˆ·ä¿¡æ¯
        for conv in shared_data["conversations"]:
            user_id = conv["user_id"]
            if user_id not in user_data_map:
                user_data_map[user_id] = {
                    "user_id": user_id,
                    "videos": [],
                    "transcripts": [],
                    "conversations": [],
                    "vectors": []
                }
            
            user_data_map[user_id]["conversations"].append(conv)
        
        # é€šè¿‡æ–‡ä»¶åå…³è”è§†é¢‘å’Œè½¬å½•æ–‡ä»¶
        video_transcript_map = {}
        for video in shared_data["videos"]:
            video_name = Path(video["filename"]).stem
            video_transcript_map[video_name] = {"video": video, "transcripts": []}
        
        for transcript in shared_data["transcripts"]:
            transcript_name = Path(transcript["filename"]).stem
            if transcript_name in video_transcript_map:
                video_transcript_map[transcript_name]["transcripts"].append(transcript)
        
        # å°†è§†é¢‘å’Œè½¬å½•æ–‡ä»¶åˆ†é…ç»™ç”¨æˆ·ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘ï¼‰
        # å¦‚æœæœ‰å¯¹è¯æ•°æ®ï¼Œå°è¯•é€šè¿‡å¯¹è¯å†…å®¹å…³è”è§†é¢‘
        for user_id, user_data in user_data_map.items():
            for conv in user_data["conversations"]:
                # ç®€å•çš„æ–‡ä»¶ååŒ¹é…é€»è¾‘
                conv_filename = Path(conv["filename"]).stem
                for video_name, vt_data in video_transcript_map.items():
                    if conv_filename in video_name or video_name in conv_filename:
                        if vt_data["video"] not in user_data["videos"]:
                            user_data["videos"].append(vt_data["video"])
                        user_data["transcripts"].extend(vt_data["transcripts"])
        
        # å¯¹äºæ— æ³•å…³è”çš„æ•°æ®ï¼Œåˆ›å»ºé»˜è®¤ç”¨æˆ·
        unassigned_videos = [v for v in shared_data["videos"] 
                           if not any(v in ud["videos"] for ud in user_data_map.values())]
        unassigned_transcripts = [t for t in shared_data["transcripts"] 
                                if not any(t in ud["transcripts"] for ud in user_data_map.values())]
        
        if unassigned_videos or unassigned_transcripts:
            default_user_id = "default_user"
            if default_user_id not in user_data_map:
                user_data_map[default_user_id] = {
                    "user_id": default_user_id,
                    "videos": [],
                    "transcripts": [],
                    "conversations": [],
                    "vectors": []
                }
            
            user_data_map[default_user_id]["videos"].extend(unassigned_videos)
            user_data_map[default_user_id]["transcripts"].extend(unassigned_transcripts)
            user_data_map[default_user_id]["vectors"] = shared_data["vectors"]
        
        logger.info(f"è¯†åˆ«å‡º {len(user_data_map)} ä¸ªç”¨æˆ·çš„æ•°æ®")
        return user_data_map
    
    def migrate_user_data(self, user_data_map: Dict[str, Dict]) -> bool:
        """
        è¿ç§»ç”¨æˆ·æ•°æ®
        
        Args:
            user_data_map: ç”¨æˆ·æ•°æ®æ˜ å°„
            
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹è¿ç§»ç”¨æˆ·æ•°æ®...")
        
        try:
            # ç¡®ä¿ç”¨æˆ·ç›®å½•å­˜åœ¨
            self.users_dir.mkdir(exist_ok=True)
            
            migration_success = True
            
            for user_id, user_data in user_data_map.items():
                logger.info(f"è¿ç§»ç”¨æˆ· {user_id} çš„æ•°æ®...")
                
                # åˆ›å»ºç”¨æˆ·ç›®å½•ç»“æ„
                user_dir = self.users_dir / user_id
                user_videos_dir = user_dir / "videos"
                user_transcripts_dir = user_dir / "transcripts"
                user_conversations_dir = user_dir / "conversations"
                user_vectors_dir = user_dir / "vectors"
                
                for dir_path in [user_dir, user_videos_dir, user_transcripts_dir, 
                               user_conversations_dir, user_vectors_dir]:
                    dir_path.mkdir(exist_ok=True)
                
                # è¿ç§»è§†é¢‘æ–‡ä»¶
                for video in user_data["videos"]:
                    try:
                        src_path = Path(video["path"])
                        dst_path = user_videos_dir / video["filename"]
                        
                        if not dst_path.exists():
                            shutil.copy2(src_path, dst_path)
                            self.migration_log.append({
                                "timestamp": datetime.now().isoformat(),
                                "user_id": user_id,
                                "action": "copy",
                                "source": str(src_path),
                                "destination": str(dst_path),
                                "status": "success"
                            })
                            logger.info(f"å¤åˆ¶è§†é¢‘æ–‡ä»¶: {video['filename']}")
                        else:
                            logger.warning(f"è§†é¢‘æ–‡ä»¶å·²å­˜åœ¨: {video['filename']}")
                    except Exception as e:
                        logger.error(f"å¤åˆ¶è§†é¢‘æ–‡ä»¶å¤±è´¥ {video['filename']}: {e}")
                        migration_success = False
                
                # è¿ç§»è½¬å½•æ–‡ä»¶
                for transcript in user_data["transcripts"]:
                    try:
                        src_path = Path(transcript["path"])
                        dst_path = user_transcripts_dir / transcript["filename"]
                        
                        if not dst_path.exists():
                            shutil.copy2(src_path, dst_path)
                            self.migration_log.append({
                                "timestamp": datetime.now().isoformat(),
                                "user_id": user_id,
                                "action": "copy",
                                "source": str(src_path),
                                "destination": str(dst_path),
                                "status": "success"
                            })
                            logger.info(f"å¤åˆ¶è½¬å½•æ–‡ä»¶: {transcript['filename']}")
                        else:
                            logger.warning(f"è½¬å½•æ–‡ä»¶å·²å­˜åœ¨: {transcript['filename']}")
                    except Exception as e:
                        logger.error(f"å¤åˆ¶è½¬å½•æ–‡ä»¶å¤±è´¥ {transcript['filename']}: {e}")
                        migration_success = False
                
                # è¿ç§»å¯¹è¯æ–‡ä»¶
                for conv in user_data["conversations"]:
                    try:
                        src_path = Path(conv["path"])
                        dst_path = user_conversations_dir / conv["filename"]
                        
                        if not dst_path.exists():
                            shutil.copy2(src_path, dst_path)
                            self.migration_log.append({
                                "timestamp": datetime.now().isoformat(),
                                "user_id": user_id,
                                "action": "copy",
                                "source": str(src_path),
                                "destination": str(dst_path),
                                "status": "success"
                            })
                            logger.info(f"å¤åˆ¶å¯¹è¯æ–‡ä»¶: {conv['filename']}")
                        else:
                            logger.warning(f"å¯¹è¯æ–‡ä»¶å·²å­˜åœ¨: {conv['filename']}")
                    except Exception as e:
                        logger.error(f"å¤åˆ¶å¯¹è¯æ–‡ä»¶å¤±è´¥ {conv['filename']}: {e}")
                        migration_success = False
                
                # è¿ç§»å‘é‡æ–‡ä»¶
                for vector in user_data["vectors"]:
                    try:
                        src_path = Path(vector["path"])
                        dst_path = user_vectors_dir / vector["filename"]
                        
                        if not dst_path.exists():
                            shutil.copy2(src_path, dst_path)
                            self.migration_log.append({
                                "timestamp": datetime.now().isoformat(),
                                "user_id": user_id,
                                "action": "copy",
                                "source": str(src_path),
                                "destination": str(dst_path),
                                "status": "success"
                            })
                            logger.info(f"å¤åˆ¶å‘é‡æ–‡ä»¶: {vector['filename']}")
                        else:
                            logger.warning(f"å‘é‡æ–‡ä»¶å·²å­˜åœ¨: {vector['filename']}")
                    except Exception as e:
                        logger.error(f"å¤åˆ¶å‘é‡æ–‡ä»¶å¤±è´¥ {vector['filename']}: {e}")
                        migration_success = False
            
            logger.info("ç”¨æˆ·æ•°æ®è¿ç§»å®Œæˆ")
            return migration_success
            
        except Exception as e:
            logger.error(f"æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False
    
    def cleanup_shared_data(self, backup: bool = True) -> bool:
        """
        æ¸…ç†å…±äº«æ•°æ®ç›®å½•
        
        Args:
            backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹æ¸…ç†å…±äº«æ•°æ®ç›®å½•...")
        
        try:
            if backup:
                # åˆ›å»ºå¤‡ä»½ç›®å½•
                backup_dir = self.base_data_dir / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                backup_dir.mkdir(exist_ok=True)
                
                # å¤‡ä»½å…±äº«æ•°æ®
                for dir_name, dir_path in self.shared_dirs.items():
                    if dir_path.exists():
                        backup_target = backup_dir / dir_name
                        shutil.copytree(dir_path, backup_target)
                        logger.info(f"å¤‡ä»½ {dir_name} åˆ° {backup_target}")
            
            # æ¸…ç†å…±äº«æ•°æ®ç›®å½•
            for dir_path in self.shared_dirs.values():
                if dir_path.exists():
                    shutil.rmtree(dir_path)
                    logger.info(f"æ¸…ç†ç›®å½•: {dir_path}")
            
            logger.info("å…±äº«æ•°æ®ç›®å½•æ¸…ç†å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç†å…±äº«æ•°æ®å¤±è´¥: {e}")
            return False
    
    def save_migration_report(self, output_path: str = None) -> str:
        """
        ä¿å­˜è¿ç§»æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = self.base_data_dir / f"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            "migration_time": datetime.now().isoformat(),
            "total_operations": len(self.migration_log),
            "successful_operations": len([log for log in self.migration_log if log["status"] == "success"]),
            "failed_operations": len([log for log in self.migration_log if log["status"] != "success"]),
            "log": self.migration_log
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¿ç§»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)
    
    def validate_migration(self) -> Dict[str, bool]:
        """
        éªŒè¯è¿ç§»ç»“æœ
        
        Returns:
            Dict[str, bool]: éªŒè¯ç»“æœ
        """
        logger.info("å¼€å§‹éªŒè¯è¿ç§»ç»“æœ...")
        
        validation_results = {}
        
        # æ£€æŸ¥ç”¨æˆ·ç›®å½•ç»“æ„
        if self.users_dir.exists():
            for user_dir in self.users_dir.iterdir():
                if user_dir.is_dir():
                    user_id = user_dir.name
                    required_dirs = ["videos", "transcripts", "conversations", "vectors"]
                    
                    for required_dir in required_dirs:
                        dir_path = user_dir / required_dir
                        validation_results[f"{user_id}_{required_dir}"] = dir_path.exists()
        
        logger.info("è¿ç§»ç»“æœéªŒè¯å®Œæˆ")
        return validation_results
    
    def _calculate_md5(self, file_path: Path) -> str:
        """
        è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: MD5å“ˆå¸Œå€¼
        """
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def run_full_migration(self, cleanup_shared: bool = True, backup: bool = True) -> bool:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®è¿ç§»æµç¨‹
        
        Args:
            cleanup_shared: æ˜¯å¦æ¸…ç†å…±äº«æ•°æ®
            backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹å®Œæ•´æ•°æ®è¿ç§»æµç¨‹...")
        
        try:
            # 1. æ‰«æå…±äº«æ•°æ®
            shared_data = self.scan_shared_data()
            
            # 2. è¯†åˆ«ç”¨æˆ·å½’å±
            user_data_map = self.identify_user_ownership(shared_data)
            
            # 3. è¿ç§»ç”¨æˆ·æ•°æ®
            migration_success = self.migrate_user_data(user_data_map)
            
            if not migration_success:
                logger.error("æ•°æ®è¿ç§»å¤±è´¥ï¼Œåœæ­¢æµç¨‹")
                return False
            
            # 4. éªŒè¯è¿ç§»ç»“æœ
            validation_results = self.validate_migration()
            if not all(validation_results.values()):
                logger.warning("è¿ç§»éªŒè¯å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
            
            # 5. ä¿å­˜è¿ç§»æŠ¥å‘Š
            report_path = self.save_migration_report()
            
            # 6. æ¸…ç†å…±äº«æ•°æ®ï¼ˆå¯é€‰ï¼‰
            if cleanup_shared:
                cleanup_success = self.cleanup_shared_data(backup=backup)
                if not cleanup_success:
                    logger.warning("å…±äº«æ•°æ®æ¸…ç†å¤±è´¥")
            
            logger.info("å®Œæ•´æ•°æ®è¿ç§»æµç¨‹å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"å®Œæ•´è¿ç§»æµç¨‹å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    migrator = DataMigrator()
    
    print("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
    success = migrator.run_full_migration(cleanup_shared=False, backup=True)
    
    if success:
        print("âœ… æ•°æ®è¿ç§»æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“Š è¿ç§»æŠ¥å‘Š: {migrator.save_migration_report()}")
    else:
        print("âŒ æ•°æ®è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    return success


if __name__ == "__main__":
    main()