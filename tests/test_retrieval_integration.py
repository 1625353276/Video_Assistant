#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€ç´¢ç³»ç»Ÿé›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯•å‘é‡å­˜å‚¨å’ŒBM25æ£€ç´¢å™¨çš„ååŒå·¥ä½œ
"""

import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.retrieval.vector_store import VectorStore
from modules.retrieval.bm25_retriever import BM25Retriever
from modules.retrieval.multi_query import MultiQueryGenerator


def load_test_transcript():
    """åŠ è½½æµ‹è¯•è½¬å½•æ•°æ®"""
    # ä½¿ç”¨æµ‹è¯•è½¬å½•æ•°æ®
    transcript_files = [
        "data/transcripts/test_transcript.json"
    ]
    
    base_path = Path(__file__).parent.parent
    
    for file_path in transcript_files:
        full_path = base_path / file_path
        if full_path.exists():
            with open(full_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'segments' in data:
                    return data['segments']
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
    return [
        {
            "id": 0,
            "start": 0.0,
            "end": 5.2,
            "text": "How does your smartphone know exactly where you are?",
            "confidence": 0.95
        },
        {
            "id": 1,
            "start": 5.2,
            "end": 10.4,
            "text": "The answer lies in a network of satellites orbiting the Earth.",
            "confidence": 0.92
        },
        {
            "id": 2,
            "start": 10.4,
            "end": 15.6,
            "text": "GPS receivers in your phone detect signals from these satellites.",
            "confidence": 0.88
        },
        {
            "id": 3,
            "start": 15.6,
            "end": 20.8,
            "text": "By measuring the time delay of signals from multiple satellites,",
            "confidence": 0.90
        },
        {
            "id": 4,
            "start": 20.8,
            "end": 26.0,
            "text": "your phone can calculate its precise location on Earth.",
            "confidence": 0.93
        }
    ]


def test_vector_store_vs_bm25():
    """æµ‹è¯•å‘é‡å­˜å‚¨å’ŒBM25æ£€ç´¢å™¨çš„å¯¹æ¯”"""
    print("=" * 60)
    print("æµ‹è¯•å‘é‡å­˜å‚¨å’ŒBM25æ£€ç´¢å™¨å¯¹æ¯”")
    print("=" * 60)
    
    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        segments = load_test_transcript()
        print(f"åŠ è½½äº† {len(segments)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        # åˆ›å»ºæ£€ç´¢å™¨
        vector_store = VectorStore()
        bm25_retriever = BM25Retriever()
        
        # æ·»åŠ æ–‡æ¡£
        print("\næ·»åŠ æ–‡æ¡£åˆ°æ£€ç´¢å™¨...")
        vector_store.add_documents(segments)
        bm25_retriever.add_documents(segments)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        vs_stats = vector_store.get_stats()
        bm25_stats = bm25_retriever.get_stats()
        
        print("\nå‘é‡å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ–‡æ¡£æ•°: {vs_stats['document_count']}")
        print(f"  å‘é‡ç»´åº¦: {vs_stats['vector_dimension']}")
        print(f"  å­˜å‚¨å¤§å°: {vs_stats['storage_size_mb']} MB")
        
        print("\nBM25æ£€ç´¢å™¨ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ–‡æ¡£æ•°: {bm25_stats['document_count']}")
        print(f"  è¯æ±‡è¡¨å¤§å°: {bm25_stats['vocabulary_size']}")
        print(f"  å¹³å‡æ–‡æ¡£é•¿åº¦: {bm25_stats['avg_doc_length']}")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
        test_queries = [
            ("GPS", "ç²¾ç¡®å…³é”®è¯åŒ¹é…"),
            ("location", "è¯­ä¹‰ç›¸å…³è¯æ±‡"),
            ("phone position", "ç»„åˆæŸ¥è¯¢"),
            ("å«æ˜Ÿå®šä½", "ä¸­æ–‡æŸ¥è¯¢"),
            ("how phone works", "å®Œæ•´å¥å­æŸ¥è¯¢")
        ]
        
        print("\n" + "=" * 40)
        print("æŸ¥è¯¢ç»“æœå¯¹æ¯”")
        print("=" * 40)
        
        for query, description in test_queries:
            print(f"\næŸ¥è¯¢: '{query}' ({description})")
            print("-" * 40)
            
            # å‘é‡å­˜å‚¨ç»“æœ
            print("\nå‘é‡å­˜å‚¨ç»“æœ:")
            try:
                vs_results = vector_store.search(query, top_k=3)
                for i, result in enumerate(vs_results):
                    doc = result["document"]
                    similarity = result["similarity"]
                    text = doc["text"][:50] + "..." if len(doc["text"]) > 50 else doc["text"]
                    print(f"  {i+1}: [ç›¸ä¼¼åº¦: {similarity:.4f}] {text}")
            except Exception as e:
                print(f"  é”™è¯¯: {str(e)}")
            
            # BM25ç»“æœ
            print("\nBM25æ£€ç´¢ç»“æœ:")
            try:
                bm25_results = bm25_retriever.search(query, top_k=3)
                for i, result in enumerate(bm25_results):
                    doc = result["document"]
                    score = result["score"]
                    text = doc["text"][:50] + "..." if len(doc["text"]) > 50 else doc["text"]
                    print(f"  {i+1}: [BM25åˆ†æ•°: {score:.4f}] {text}")
            except Exception as e:
                print(f"  é”™è¯¯: {str(e)}")
        
        print("\nâœ… å‘é‡å­˜å‚¨å’ŒBM25æ£€ç´¢å™¨å¯¹æ¯”æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    return True


def test_hybrid_retrieval_concept():
    """æµ‹è¯•æ··åˆæ£€ç´¢æ¦‚å¿µï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ··åˆæ£€ç´¢æ¦‚å¿µï¼ˆæ¨¡æ‹Ÿï¼‰")
    print("=" * 60)
    
    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        segments = load_test_transcript()
        
        # åˆ›å»ºæ£€ç´¢å™¨
        vector_store = VectorStore()
        bm25_retriever = BM25Retriever()
        
        # æ·»åŠ æ–‡æ¡£
        vector_store.add_documents(segments)
        bm25_retriever.add_documents(segments)
        
        # æµ‹è¯•æŸ¥è¯¢
        query = "GPS satellite location"
        print(f"æµ‹è¯•æŸ¥è¯¢: '{query}'")
        
        # è·å–æ£€ç´¢ç»“æœ
        vs_results = vector_store.search(query, top_k=5)
        bm25_results = bm25_retriever.search(query, top_k=5)
        
        # ç®€å•çš„æ··åˆæ£€ç´¢ï¼šåˆå¹¶å¹¶é‡æ–°æ’åº
        all_docs = {}
        
        # æ·»åŠ å‘é‡å­˜å‚¨ç»“æœ
        for result in vs_results:
            doc_id = result["document"]["id"]
            all_docs[doc_id] = {
                "document": result["document"],
                "vector_similarity": result["similarity"],
                "bm25_score": 0.0
            }
        
        # æ·»åŠ BM25ç»“æœ
        for result in bm25_results:
            doc_id = result["document"]["id"]
            if doc_id in all_docs:
                all_docs[doc_id]["bm25_score"] = result["score"]
            else:
                all_docs[doc_id] = {
                    "document": result["document"],
                    "vector_similarity": 0.0,
                    "bm25_score": result["score"]
                }
        
        # è®¡ç®—æ··åˆåˆ†æ•°ï¼ˆç®€å•åŠ æƒï¼‰
        hybrid_results = []
        for doc_id, doc_data in all_docs.items():
            # å½’ä¸€åŒ–åˆ†æ•°
            vector_score = min(doc_data["vector_similarity"], 1.0)
            bm25_score = min(doc_data["bm25_score"] / 10.0, 1.0)  # ç®€å•å½’ä¸€åŒ–
            
            # æ··åˆåˆ†æ•°ï¼ˆå¯è°ƒæ•´æƒé‡ï¼‰
            hybrid_score = 0.6 * vector_score + 0.4 * bm25_score
            
            hybrid_results.append({
                "document": doc_data["document"],
                "vector_similarity": doc_data["vector_similarity"],
                "bm25_score": doc_data["bm25_score"],
                "hybrid_score": hybrid_score
            })
        
        # æŒ‰æ··åˆåˆ†æ•°æ’åº
        hybrid_results.sort(key=lambda x: x["hybrid_score"], reverse=True)
        
        # æ˜¾ç¤ºç»“æœ
        print("\næ··åˆæ£€ç´¢ç»“æœ:")
        print("-" * 60)
        print(f"{'æ’å':<4} {'æ··åˆåˆ†æ•°':<10} {'å‘é‡ç›¸ä¼¼åº¦':<12} {'BM25åˆ†æ•°':<10} {'æ–‡æœ¬ç‰‡æ®µ'}")
        print("-" * 60)
        
        for i, result in enumerate(hybrid_results[:5]):
            doc = result["document"]
            text = doc["text"][:40] + "..." if len(doc["text"]) > 40 else doc["text"]
            print(f"{i+1:<4} {result['hybrid_score']:<10.4f} {result['vector_similarity']:<12.4f} "
                  f"{result['bm25_score']:<10.4f} {text}")
        
        print("\nâœ… æ··åˆæ£€ç´¢æ¦‚å¿µæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    return True


def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)
    
    try:
        import time
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        segments = load_test_transcript()
        
        # åˆ›å»ºæ£€ç´¢å™¨
        vector_store = VectorStore()
        bm25_retriever = BM25Retriever()
        
        # æµ‹è¯•ç´¢å¼•æ„å»ºæ—¶é—´
        print("æµ‹è¯•ç´¢å¼•æ„å»ºæ—¶é—´:")
        
        start_time = time.time()
        vector_store.add_documents(segments)
        vs_index_time = time.time() - start_time
        print(f"  å‘é‡å­˜å‚¨ç´¢å¼•æ„å»º: {vs_index_time:.4f} ç§’")
        
        start_time = time.time()
        bm25_retriever.add_documents(segments)
        bm25_index_time = time.time() - start_time
        print(f"  BM25ç´¢å¼•æ„å»º: {bm25_index_time:.4f} ç§’")
        
        # æµ‹è¯•æŸ¥è¯¢æ—¶é—´
        test_queries = ["GPS", "location", "satellite", "phone"]
        
        print("\næµ‹è¯•æŸ¥è¯¢æ—¶é—´:")
        print(f"{'æŸ¥è¯¢':<12} {'å‘é‡å­˜å‚¨':<12} {'BM25':<12}")
        print("-" * 36)
        
        for query in test_queries:
            # å‘é‡å­˜å‚¨æŸ¥è¯¢æ—¶é—´
            start_time = time.time()
            vector_store.search(query, top_k=3)
            vs_query_time = time.time() - start_time
            
            # BM25æŸ¥è¯¢æ—¶é—´
            start_time = time.time()
            bm25_retriever.search(query, top_k=3)
            bm25_query_time = time.time() - start_time
            
            print(f"{query:<12} {vs_query_time:<12.4f} {bm25_query_time:<12.4f}")
        
        print("\nâœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    return True


def test_multi_query_integration():
    """æµ‹è¯•å¤šæŸ¥è¯¢ç”Ÿæˆå™¨ä¸æ£€ç´¢ç³»ç»Ÿçš„é›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¤šæŸ¥è¯¢ç”Ÿæˆå™¨é›†æˆ")
    print("=" * 60)
    
    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        segments = load_test_transcript()
        print(f"åŠ è½½äº† {len(segments)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        # åˆ›å»ºæ£€ç´¢å™¨å’Œå¤šæŸ¥è¯¢ç”Ÿæˆå™¨
        vector_store = VectorStore()
        bm25_retriever = BM25Retriever()
        multi_query_generator = MultiQueryGenerator(
            max_queries=5
        )
        
        # æ·»åŠ æ–‡æ¡£
        print("\næ·»åŠ æ–‡æ¡£åˆ°æ£€ç´¢å™¨...")
        vector_store.add_documents(segments)
        bm25_retriever.add_documents(segments)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "GPSå®šä½æŠ€æœ¯",
            "smartphone location", 
            "å«æ˜Ÿå¯¼èˆªç³»ç»Ÿ"
        ]
        
        print("\nå¤šæŸ¥è¯¢ç”Ÿæˆå’Œæ£€ç´¢æµ‹è¯•:")
        print("=" * 60)
        
        for query in test_queries:
            print(f"\nåŸå§‹æŸ¥è¯¢: '{query}'")
            print("-" * 40)
            
            # ç”Ÿæˆå¤šæŸ¥è¯¢
            multi_result = multi_query_generator.generate_queries(query)
            print(f"ç”Ÿæˆäº† {len(multi_result.generated_queries)} ä¸ªæŸ¥è¯¢:")
            
            for i, q in enumerate(multi_result.generated_queries):
                print(f"  {i+1}. {q.query} [æƒé‡: {q.weight:.3f}] [æ–¹æ³•: {q.method}]")
            
            # å¯¹æ¯ä¸ªç”Ÿæˆçš„æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
            print("\næ£€ç´¢ç»“æœ:")
            print(f"{'æŸ¥è¯¢':<20} {'å‘é‡ç»“æœ':<8} {'BM25ç»“æœ':<8} {'æœ€ä½³åŒ¹é…'}")
            print("-" * 60)
            
            all_results = {}
            
            for q in multi_result.generated_queries:
                # å‘é‡å­˜å‚¨æ£€ç´¢
                try:
                    vs_results = vector_store.search(q.query, top_k=1)
                    vs_count = len(vs_results)
                    vs_best = vs_results[0]["document"]["text"][:30] + "..." if vs_results else "æ— "
                except:
                    vs_count = 0
                    vs_best = "é”™è¯¯"
                
                # BM25æ£€ç´¢
                try:
                    bm25_results = bm25_retriever.search(q.query, top_k=1)
                    bm25_count = len(bm25_results)
                    bm25_best = bm25_results[0]["document"]["text"][:30] + "..." if bm25_results else "æ— "
                except:
                    bm25_count = 0
                    bm25_best = "é”™è¯¯"
                
                # è®°å½•ç»“æœ
                all_results[q.query] = {
                    "weight": q.weight,
                    "vs_count": vs_count,
                    "bm25_count": bm25_count,
                    "vs_best": vs_best,
                    "bm25_best": bm25_best
                }
                
                print(f"{q.query[:20]:<20} {vs_count:<8} {bm25_count:<8} {vs_best}")
            
            # åˆ†æå¤šæŸ¥è¯¢æ•ˆæœ
            print(f"\nå¤šæŸ¥è¯¢æ•ˆæœåˆ†æ:")
            total_vs_results = sum(r["vs_count"] for r in all_results.values())
            total_bm25_results = sum(r["bm25_count"] for r in all_results.values())
            
            print(f"  æ€»å‘é‡æ£€ç´¢ç»“æœ: {total_vs_results}")
            print(f"  æ€»BM25æ£€ç´¢ç»“æœ: {total_bm25_results}")
            print(f"  å¹³å‡æ¯æŸ¥è¯¢å‘é‡ç»“æœ: {total_vs_results/len(all_results):.1f}")
            print(f"  å¹³å‡æ¯æŸ¥è¯¢BM25ç»“æœ: {total_bm25_results/len(all_results):.1f}")
        
        print("\nâœ… å¤šæŸ¥è¯¢ç”Ÿæˆå™¨é›†æˆæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    return True


def test_multi_query_enhanced_retrieval():
    """æµ‹è¯•å¤šæŸ¥è¯¢å¢å¼ºæ£€ç´¢æ•ˆæœ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¤šæŸ¥è¯¢å¢å¼ºæ£€ç´¢æ•ˆæœ")
    print("=" * 60)
    
    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        segments = load_test_transcript()
        
        # åˆ›å»ºæ£€ç´¢å™¨å’Œå¤šæŸ¥è¯¢ç”Ÿæˆå™¨
        vector_store = VectorStore()
        bm25_retriever = BM25Retriever()
        multi_query_generator = MultiQueryGenerator(
            max_queries=8
        )
        
        # æ·»åŠ æ–‡æ¡£
        vector_store.add_documents(segments)
        bm25_retriever.add_documents(segments)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "æ‰‹æœºå®šä½åŸç†"
        
        print(f"æµ‹è¯•æŸ¥è¯¢: '{test_query}'")
        print("=" * 40)
        
        # å•æŸ¥è¯¢æ£€ç´¢
        print("\nå•æŸ¥è¯¢æ£€ç´¢ç»“æœ:")
        vs_single = vector_store.search(test_query, top_k=5)
        bm25_single = bm25_retriever.search(test_query, top_k=5)
        
        print(f"å‘é‡å­˜å‚¨: {len(vs_single)} ä¸ªç»“æœ")
        for i, result in enumerate(vs_single):
            text = result["document"]["text"][:50] + "..."
            print(f"  {i+1}. [ç›¸ä¼¼åº¦: {result['similarity']:.3f}] {text}")
        
        print(f"\nBM25æ£€ç´¢: {len(bm25_single)} ä¸ªç»“æœ")
        for i, result in enumerate(bm25_single):
            text = result["document"]["text"][:50] + "..."
            print(f"  {i+1}. [åˆ†æ•°: {result['score']:.3f}] {text}")
        
        # å¤šæŸ¥è¯¢å¢å¼ºæ£€ç´¢
        print(f"\nå¤šæŸ¥è¯¢å¢å¼ºæ£€ç´¢ç»“æœ:")
        multi_result = multi_query_generator.generate_queries(test_query)
        
        # æ”¶é›†æ‰€æœ‰æ£€ç´¢ç»“æœ
        all_vs_docs = {}
        all_bm25_docs = {}
        
        for q in multi_result.generated_queries:
            # å‘é‡å­˜å‚¨æ£€ç´¢
            vs_results = vector_store.search(q.query, top_k=3)
            for result in vs_results:
                doc_id = result["document"]["id"]
                if doc_id not in all_vs_docs:
                    all_vs_docs[doc_id] = {
                        "document": result["document"],
                        "max_similarity": result["similarity"],
                        "query_hits": []
                    }
                else:
                    all_vs_docs[doc_id]["max_similarity"] = max(
                        all_vs_docs[doc_id]["max_similarity"], 
                        result["similarity"]
                    )
                all_vs_docs[doc_id]["query_hits"].append(q.query)
            
            # BM25æ£€ç´¢
            bm25_results = bm25_retriever.search(q.query, top_k=3)
            for result in bm25_results:
                doc_id = result["document"]["id"]
                if doc_id not in all_bm25_docs:
                    all_bm25_docs[doc_id] = {
                        "document": result["document"],
                        "max_score": result["score"],
                        "query_hits": []
                    }
                else:
                    all_bm25_docs[doc_id]["max_score"] = max(
                        all_bm25_docs[doc_id]["max_score"], 
                        result["score"]
                    )
                all_bm25_docs[doc_id]["query_hits"].append(q.query)
        
        # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
        print(f"\nå¢å¼ºå‘é‡æ£€ç´¢: {len(all_vs_docs)} ä¸ªå”¯ä¸€ç»“æœ")
        sorted_vs = sorted(all_vs_docs.values(), key=lambda x: x["max_similarity"], reverse=True)
        for i, doc_data in enumerate(sorted_vs[:5]):
            text = doc_data["document"]["text"][:50] + "..."
            print(f"  {i+1}. [ç›¸ä¼¼åº¦: {doc_data['max_similarity']:.3f}] {text}")
            print(f"      åŒ¹é…æŸ¥è¯¢: {', '.join(doc_data['query_hits'])}")
        
        print(f"\nå¢å¼ºBM25æ£€ç´¢: {len(all_bm25_docs)} ä¸ªå”¯ä¸€ç»“æœ")
        sorted_bm25 = sorted(all_bm25_docs.values(), key=lambda x: x["max_score"], reverse=True)
        for i, doc_data in enumerate(sorted_bm25[:5]):
            text = doc_data["document"]["text"][:50] + "..."
            print(f"  {i+1}. [åˆ†æ•°: {doc_data['max_score']:.3f}] {text}")
            print(f"      åŒ¹é…æŸ¥è¯¢: {', '.join(doc_data['query_hits'])}")
        
        # æ•ˆæœå¯¹æ¯”
        print(f"\næ£€ç´¢æ•ˆæœå¯¹æ¯”:")
        print(f"  å•æŸ¥è¯¢å‘é‡æ£€ç´¢: {len(vs_single)} ä¸ªç»“æœ")
        print(f"  å¤šæŸ¥è¯¢å‘é‡æ£€ç´¢: {len(all_vs_docs)} ä¸ªç»“æœ")
        print(f"  å¬å›ç‡æå‡: {((len(all_vs_docs) - len(vs_single)) / len(vs_single) * 100):.1f}%")
        print(f"  å•æŸ¥è¯¢BM25æ£€ç´¢: {len(bm25_single)} ä¸ªç»“æœ")
        print(f"  å¤šæŸ¥è¯¢BM25æ£€ç´¢: {len(all_bm25_docs)} ä¸ªç»“æœ")
        print(f"  å¬å›ç‡æå‡: {((len(all_bm25_docs) - len(bm25_single)) / max(len(bm25_single), 1) * 100):.1f}%")
        
        print("\nâœ… å¤šæŸ¥è¯¢å¢å¼ºæ£€ç´¢æ•ˆæœæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    return True


def main():
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    print("å¼€å§‹æ£€ç´¢ç³»ç»Ÿé›†æˆæµ‹è¯•")
    print("=" * 60)
    
    tests = [
        test_vector_store_vs_bm25,
        test_hybrid_retrieval_concept,
        test_performance_comparison,
        test_multi_query_integration,
        test_multi_query_enhanced_retrieval
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        if test_func():
            passed += 1
    
    print("\n" + "=" * 60)
    print("é›†æˆæµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"é€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ£€ç´¢ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print(f"âš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)