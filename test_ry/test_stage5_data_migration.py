#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬äº”é˜¶æ®µæµ‹è¯•ï¼šæ•°æ®è¿ç§»å’Œæ¸…ç†

æµ‹è¯•æ•°æ®ä»å…±äº«ç›®å½•è¿ç§»åˆ°ç”¨æˆ·éš”ç¦»ç›®å½•çš„åŠŸèƒ½
"""

import sys
import os
import json
import tempfile
import shutil
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from deploy.utils.data_migrator import DataMigrator


def create_test_data_structure(base_dir: Path):
    """åˆ›å»ºæµ‹è¯•æ•°æ®ç»“æ„"""
    # åˆ›å»ºå…±äº«æ•°æ®ç›®å½•
    shared_dirs = {
        "videos": base_dir / "data" / "raw_videos",
        "transcripts": base_dir / "data" / "transcripts",
        "conversations": base_dir / "data" / "memory",
        "vectors": base_dir / "data" / "vectors"
    }
    
    for dir_path in shared_dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•è§†é¢‘æ–‡ä»¶
    test_video = shared_dirs["videos"] / "test_video.mp4"
    test_video.write_bytes(b"fake video content")
    
    # åˆ›å»ºæµ‹è¯•è½¬å½•æ–‡ä»¶
    test_transcript = shared_dirs["transcripts"] / "test_video_transcript.json"
    transcript_data = {
        "text": "è¿™æ˜¯æµ‹è¯•è½¬å½•æ–‡æœ¬",
        "segments": [
            {"id": 0, "start": 0.0, "end": 5.0, "text": "ç¬¬ä¸€æ®µæµ‹è¯•å†…å®¹"},
            {"id": 1, "start": 5.0, "end": 10.0, "text": "ç¬¬äºŒæ®µæµ‹è¯•å†…å®¹"}
        ]
    }
    test_transcript.write_text(json.dumps(transcript_data, ensure_ascii=False, indent=2), encoding='utf-8')
    
    # åˆ›å»ºæµ‹è¯•å¯¹è¯æ–‡ä»¶
    test_conversation = shared_dirs["conversations"] / "test_video_conversation.json"
    conversation_data = {
        "user_id": "test_user_123",
        "session_id": "test_session",
        "created_at": datetime.now().isoformat(),
        "history": [
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"},
            {"role": "assistant", "content": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯..."}
        ]
    }
    test_conversation.write_text(json.dumps(conversation_data, ensure_ascii=False, indent=2), encoding='utf-8')
    
    # åˆ›å»ºæµ‹è¯•å‘é‡æ–‡ä»¶
    test_vector = shared_dirs["vectors"] / "test_vector_index.pkl"
    test_vector.write_bytes(b"fake vector data")
    
    return shared_dirs


def test_data_migrator_init():
    """æµ‹è¯•æ•°æ®è¿ç§»å™¨åˆå§‹åŒ–"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®è¿ç§»å™¨åˆå§‹åŒ–...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        migrator = DataMigrator(base_data_dir=os.path.join(temp_dir, "data"))
        
        assert migrator.base_data_dir == Path(os.path.join(temp_dir, "data"))
        assert isinstance(migrator.shared_dirs, dict)
        assert isinstance(migrator.users_dir, Path)
        assert isinstance(migrator.migration_log, list)
        
        print("âœ… æ•°æ®è¿ç§»å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")


def test_scan_shared_data():
    """æµ‹è¯•æ‰«æå…±äº«æ•°æ®"""
    print("ğŸ§ª æµ‹è¯•æ‰«æå…±äº«æ•°æ®...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        shared_dirs = create_test_data_structure(temp_path)
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰«æ
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        shared_data = migrator.scan_shared_data()
        
        # éªŒè¯æ‰«æç»“æœ
        assert len(shared_data["videos"]) == 1
        assert len(shared_data["transcripts"]) == 1
        assert len(shared_data["conversations"]) == 1
        assert len(shared_data["vectors"]) == 1
        
        # éªŒè¯è§†é¢‘æ•°æ®
        video = shared_data["videos"][0]
        assert video["filename"] == "test_video.mp4"
        assert "md5" in video
        assert "size" in video
        
        # éªŒè¯è½¬å½•æ•°æ®
        transcript = shared_data["transcripts"][0]
        assert transcript["filename"] == "test_video_transcript.json"
        assert transcript["type"] == ".json"
        
        # éªŒè¯å¯¹è¯æ•°æ®
        conversation = shared_data["conversations"][0]
        assert conversation["filename"] == "test_video_conversation.json"
        assert conversation["user_id"] == "test_user_123"
        assert "data" in conversation
        
        print("âœ… æ‰«æå…±äº«æ•°æ®æµ‹è¯•é€šè¿‡")


def test_identify_user_ownership():
    """æµ‹è¯•è¯†åˆ«ç”¨æˆ·å½’å±"""
    print("ğŸ§ª æµ‹è¯•è¯†åˆ«ç”¨æˆ·å½’å±...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        shared_dirs = create_test_data_structure(temp_path)
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰«æ
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        shared_data = migrator.scan_shared_data()
        
        # è¯†åˆ«ç”¨æˆ·å½’å±
        user_data_map = migrator.identify_user_ownership(shared_data)
        
        # éªŒè¯ç”¨æˆ·æ•°æ®æ˜ å°„
        assert "test_user_123" in user_data_map
        assert "default_user" in user_data_map  # æœªåˆ†é…æ•°æ®çš„é»˜è®¤ç”¨æˆ·
        
        # éªŒè¯ç”¨æˆ·æ•°æ®
        user_data = user_data_map["test_user_123"]
        assert user_data["user_id"] == "test_user_123"
        assert len(user_data["conversations"]) == 1
        assert isinstance(user_data["videos"], list)
        assert isinstance(user_data["transcripts"], list)
        assert isinstance(user_data["vectors"], list)
        
        print("âœ… è¯†åˆ«ç”¨æˆ·å½’å±æµ‹è¯•é€šè¿‡")


def test_migrate_user_data():
    """æµ‹è¯•è¿ç§»ç”¨æˆ·æ•°æ®"""
    print("ğŸ§ª æµ‹è¯•è¿ç§»ç”¨æˆ·æ•°æ®...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        shared_dirs = create_test_data_structure(temp_path)
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰«æ
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        shared_data = migrator.scan_shared_data()
        user_data_map = migrator.identify_user_ownership(shared_data)
        
        # æ‰§è¡Œè¿ç§»
        migration_success = migrator.migrate_user_data(user_data_map)
        
        # éªŒè¯è¿ç§»ç»“æœ
        assert migration_success is True
        assert len(migrator.migration_log) > 0
        
        # éªŒè¯ç”¨æˆ·ç›®å½•ç»“æ„
        users_dir = temp_path / "data" / "users"
        assert users_dir.exists()
        
        # éªŒè¯test_user_123çš„ç›®å½•
        test_user_dir = users_dir / "test_user_123"
        assert test_user_dir.exists()
        
        # éªŒè¯å­ç›®å½•
        for subdir in ["videos", "transcripts", "conversations", "vectors"]:
            assert (test_user_dir / subdir).exists()
        
        # éªŒè¯æ–‡ä»¶è¿ç§»
        assert (test_user_dir / "conversations" / "test_video_conversation.json").exists()
        
        print("âœ… è¿ç§»ç”¨æˆ·æ•°æ®æµ‹è¯•é€šè¿‡")


def test_validate_migration():
    """æµ‹è¯•éªŒè¯è¿ç§»ç»“æœ"""
    print("ğŸ§ª æµ‹è¯•éªŒè¯è¿ç§»ç»“æœ...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®å¹¶è¿ç§»
        shared_dirs = create_test_data_structure(temp_path)
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        shared_data = migrator.scan_shared_data()
        user_data_map = migrator.identify_user_ownership(shared_data)
        migrator.migrate_user_data(user_data_map)
        
        # éªŒè¯è¿ç§»ç»“æœ
        validation_results = migrator.validate_migration()
        
        # éªŒè¯ç»“æœ
        assert isinstance(validation_results, dict)
        assert len(validation_results) > 0
        
        # æ£€æŸ¥å…³é”®éªŒè¯é¡¹
        assert "test_user_123_videos" in validation_results
        assert "test_user_123_transcripts" in validation_results
        assert "test_user_123_conversations" in validation_results
        assert "test_user_123_vectors" in validation_results
        
        # æ‰€æœ‰éªŒè¯é¡¹åº”è¯¥éƒ½ä¸ºTrue
        assert all(validation_results.values())
        
        print("âœ… éªŒè¯è¿ç§»ç»“æœæµ‹è¯•é€šè¿‡")


def test_save_migration_report():
    """æµ‹è¯•ä¿å­˜è¿ç§»æŠ¥å‘Š"""
    print("ğŸ§ª æµ‹è¯•ä¿å­˜è¿ç§»æŠ¥å‘Š...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰§è¡Œè¿ç§»
        shared_dirs = create_test_data_structure(temp_path)
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        shared_data = migrator.scan_shared_data()
        user_data_map = migrator.identify_user_ownership(shared_data)
        migrator.migrate_user_data(user_data_map)
        
        # ä¿å­˜è¿ç§»æŠ¥å‘Š
        report_path = migrator.save_migration_report()
        
        # éªŒè¯æŠ¥å‘Šæ–‡ä»¶
        assert Path(report_path).exists()
        
        # éªŒè¯æŠ¥å‘Šå†…å®¹
        with open(report_path, 'r', encoding='utf-8') as f:
            report_data = json.load(f)
        
        assert "migration_time" in report_data
        assert "total_operations" in report_data
        assert "successful_operations" in report_data
        assert "failed_operations" in report_data
        assert "log" in report_data
        
        # éªŒè¯æ—¥å¿—å†…å®¹
        assert len(report_data["log"]) > 0
        assert report_data["log"][0]["action"] == "copy"
        assert report_data["log"][0]["status"] == "success"
        
        print("âœ… ä¿å­˜è¿ç§»æŠ¥å‘Šæµ‹è¯•é€šè¿‡")


def test_cleanup_shared_data():
    """æµ‹è¯•æ¸…ç†å…±äº«æ•°æ®"""
    print("ğŸ§ª æµ‹è¯•æ¸…ç†å…±äº«æ•°æ®...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        shared_dirs = create_test_data_structure(temp_path)
        
        # éªŒè¯æ•°æ®å­˜åœ¨
        for dir_path in shared_dirs.values():
            assert dir_path.exists()
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ¸…ç†
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        cleanup_success = migrator.cleanup_shared_data(backup=True)
        
        # éªŒè¯æ¸…ç†ç»“æœ
        assert cleanup_success is True
        
        # éªŒè¯å…±äº«ç›®å½•å·²æ¸…ç†
        for dir_path in shared_dirs.values():
            assert not dir_path.exists()
        
        # éªŒè¯å¤‡ä»½ç›®å½•å·²åˆ›å»º
        backup_dirs = list((temp_path / "data").glob("backup_*"))
        assert len(backup_dirs) == 1
        
        # éªŒè¯å¤‡ä»½æ•°æ®
        backup_dir = backup_dirs[0]
        # æ£€æŸ¥å¤‡ä»½ç›®å½•ä¸­æ˜¯å¦æœ‰å†…å®¹
        backup_subdirs = [d for d in backup_dir.iterdir() if d.is_dir()]
        assert len(backup_subdirs) >= 1  # è‡³å°‘æœ‰ä¸€ä¸ªå¤‡ä»½ç›®å½•
        
        # éªŒè¯å¤‡ä»½ç›®å½•åŒ…å«é¢„æœŸçš„æ•°æ®
        backup_has_data = False
        for subdir in backup_subdirs:
            if subdir.name in ["raw_videos", "transcripts", "memory", "vectors"]:
                backup_has_data = True
                break
        assert backup_has_data
        
        print("âœ… æ¸…ç†å…±äº«æ•°æ®æµ‹è¯•é€šè¿‡")


def test_full_migration():
    """æµ‹è¯•å®Œæ•´è¿ç§»æµç¨‹"""
    print("ğŸ§ª æµ‹è¯•å®Œæ•´è¿ç§»æµç¨‹...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        shared_dirs = create_test_data_structure(temp_path)
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶æ‰§è¡Œå®Œæ•´æµç¨‹
        migrator = DataMigrator(base_data_dir=str(temp_path / "data"))
        migration_success = migrator.run_full_migration(cleanup_shared=False, backup=True)
        
        # éªŒè¯è¿ç§»æˆåŠŸ
        assert migration_success is True
        
        # éªŒè¯ç”¨æˆ·æ•°æ®å·²è¿ç§»
        users_dir = temp_path / "data" / "users"
        assert users_dir.exists()
        
        # éªŒè¯è¿ç§»æŠ¥å‘Šå·²ç”Ÿæˆ
        report_files = list((temp_path / "data").glob("migration_report_*.json"))
        assert len(report_files) == 1
        
        # éªŒè¯å…±äº«æ•°æ®ä»ç„¶å­˜åœ¨ï¼ˆå› ä¸ºcleanup_shared=Falseï¼‰
        for dir_path in shared_dirs.values():
            assert dir_path.exists()
        
        print("âœ… å®Œæ•´è¿ç§»æµç¨‹æµ‹è¯•é€šè¿‡")


def test_md5_calculation():
    """æµ‹è¯•MD5è®¡ç®—"""
    print("ğŸ§ª æµ‹è¯•MD5è®¡ç®—...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = temp_path / "test.txt"
        test_content = "Hello, World!"
        test_file.write_text(test_content, encoding='utf-8')
        
        # åˆ›å»ºè¿ç§»å™¨å¹¶è®¡ç®—MD5
        migrator = DataMigrator()
        md5_hash = migrator._calculate_md5(test_file)
        
        # éªŒè¯MD5ç»“æœ
        assert isinstance(md5_hash, str)
        assert len(md5_hash) == 32  # MD5å“ˆå¸Œé•¿åº¦
        
        # éªŒè¯ç›¸åŒå†…å®¹äº§ç”Ÿç›¸åŒå“ˆå¸Œ
        test_file2 = temp_path / "test2.txt"
        test_file2.write_text(test_content, encoding='utf-8')
        md5_hash2 = migrator._calculate_md5(test_file2)
        assert md5_hash == md5_hash2
        
        # éªŒè¯ä¸åŒå†…å®¹äº§ç”Ÿä¸åŒå“ˆå¸Œ
        test_file3 = temp_path / "test3.txt"
        test_file3.write_text("Different content", encoding='utf-8')
        md5_hash3 = migrator._calculate_md5(test_file3)
        assert md5_hash != md5_hash3
        
        print("âœ… MD5è®¡ç®—æµ‹è¯•é€šè¿‡")


def run_stage5_tests():
    """è¿è¡Œç¬¬äº”é˜¶æ®µæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ç¬¬äº”é˜¶æ®µæµ‹è¯•ï¼šæ•°æ®è¿ç§»å’Œæ¸…ç†\n")
    
    try:
        test_data_migrator_init()
        print()
        test_scan_shared_data()
        print()
        test_identify_user_ownership()
        print()
        test_migrate_user_data()
        print()
        test_validate_migration()
        print()
        test_save_migration_report()
        print()
        test_cleanup_shared_data()
        print()
        test_full_migration()
        print()
        test_md5_calculation()
        print()
        
        print("ğŸ‰ ç¬¬äº”é˜¶æ®µæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… æ•°æ®è¿ç§»å™¨å®ç°å®Œæˆ")
        print("âœ… å…±äº«æ•°æ®æ‰«æåŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… ç”¨æˆ·å½’å±è¯†åˆ«åŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… ç”¨æˆ·æ•°æ®è¿ç§»åŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… è¿ç§»ç»“æœéªŒè¯åŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… è¿ç§»æŠ¥å‘Šç”ŸæˆåŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… å…±äº«æ•°æ®æ¸…ç†åŠŸèƒ½å®ç°å®Œæˆ")
        print("âœ… å®Œæ•´è¿ç§»æµç¨‹å®ç°å®Œæˆ")
        print("âœ… MD5æ–‡ä»¶æ ¡éªŒåŠŸèƒ½å®ç°å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_stage5_tests()
    sys.exit(0 if success else 1)
